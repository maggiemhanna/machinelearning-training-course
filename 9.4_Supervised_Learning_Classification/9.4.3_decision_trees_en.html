<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
A visual introduction to decision trees
</title>

    <link rel="shortcut icon" href="http://www.r2d3.us/static/app/global/favicon.ico">
    <!-- Bootstrap -->
    <link href="http://www.r2d3.us/static/app/_bower_components/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="http://www.r2d3.us/static/app/global/style.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    

<link href="http://www.r2d3.us/static/pages/decision-trees-part-1/styles.css" rel="stylesheet">

<script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function(event) { 
    var dismissText = document.getElementById("dismiss-disclaimer")
    var removeDisclaimer
  
    removeDisclaimer = function() {
      var disclaimer = document.getElementById('resolution-disclaimer')
      disclaimer.remove()
  
      dismissText.removeEventListener("click", removeDisclaimer, false)
    }
  
    dismissText.addEventListener("click", removeDisclaimer, false)
  });  
</script>
<style>
  #resolution-disclaimer {
    display: none;
  }
  
  @media (max-width: 1023px) and (max-height: 767px) {
    #resolution-disclaimer {
      z-index: 10000;
      display: block;
      position: fixed;
      bottom: 0;
      left: 0;
      width: 100vw;
      background: rgba(0,0,0,0.85);
    }
  
    #disclaimer-wrapper {
      width: 95vw;
      margin: 20px auto;
      color: #fff;
    }
  
    #dismiss-disclaimer {
      text-decoration: underline;
      cursor: pointer;
      color: #777;
    }
  }</style>  



  </head>
  <body>
    <div id="header">
      <div class="container">
        <div class="row">
          <div class="col-xs-11 col-sm-4">
          </div>
        </div>
      </div>
    </div>
    

<div class="container" id="main">
	<div class="row" id="intro">
		<div class="col-xs-5">
			<div id="set-up" class="tracking-section">
				<h1>A visual introduction to decision trees</h1>
				<p><strong>Decision Trees</strong> are a powerful class of Machine Learning capable of achieving good accuracy in many tasks while being highly interpretable.</p>
				<p>Decision Trees are a non-parametric supervised learning method used for <strong>classification</strong> and <strong>regressions</strong>. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.
				<p>Using a data set about homes, we will create a decision tree model to distinguish homes in New York from homes in San Francisco. </p>
			</div>
			<div id="keep-scrolling">
				<div id="animated-arrow">
					<p>Scroll</p>
					<svg width="40" height="10">
						<path d="M0,0L40,0L20,10Z" fill="#000" stroke="none" />
					</svg>
				</div>
			</div>
			<hr class="whitespace" style="height: 30vh;" />
			<div id="first-two" class="tracking-section">
				<h2> First, some intuition </h2>
				<p> Let&rsquo;s&nbsp;say you had to determine whether a home is in <strong style="color:rgb(65, 153, 43);"> San Francisco</strong> or in <strong style="color:rgb(16, 70, 131);">New York</strong>. Categorizing data points is a <strong>classification</strong> task. </p>
				<p> Since San Francisco is relatively hilly, the elevation of a home may be a good way to distinguish the two cities. </p>
				<p> Based on the home-elevation data to the right, you could argue that a home above 73 meters (239.5 ft) should be <strong> classified</strong> as one in San Francisco. </p>
			</div>
			<hr class="whitespace" style="height: 40vh;" />
			<div id="add-nuance">
				<h2> Adding nuance </h2>
				<p> Adding another <strong>feature / predictor</strong> allows for more nuance. For example, New York apartments can be extremely expensive per square foot. </p>
				<p> So visualizing elevation <em>and</em> price per square foot in a <strong>scatterplot</strong> helps us distinguish lower-elevation homes. </p>
				<p> The data suggests that, among homes at or below 73 meters (239.5 ft), those that cost more than $19,116.7 per square meter are in New York City. </p>
			</div>
			<hr class="whitespace" style="height: 30vh;" />
			<div id="set-boundaries" class="tracking-section">
				<h2> Drawing boundaries </h2>
				<p> You can visualize your elevation (>73 m) and price per square foot (>$19,116.7) observations as the boundaries of regions in your scatterplot. Homes plotted in the green and blue regions would be in San Francisco and New York, respectively. </p>
				<p> Identifying boundaries in data using math is the essence of decision trees. </p>
				<p> Of course, you&rsquo;ll need additional information to distinguish homes with lower elevations <em>and</em> lower per-square-foot prices. </p>
			</div>
			<hr class="whitespace" style="height: 55vh;" />
			<div id="more-variables">
				<div id="getting-more-data" class="tracking-section">
				</div>
				<div id="listing-the-variables">
					<!--<div id="data-table"></div>-->
				<p> The dataset we are using to create the model has 7 different dimensions. We will create / <strong>train</strong> a model using these 7 features. </p>
				<p> On the right, we are visualizing the variables in a <strong>scatterplot matrix</strong> to show the relationships between each pair of dimensions. </p>
				<p> There are clearly patterns in the data, but the boundaries for delineating them are not obvious. </p>
				</div>
				<div id="from-boundaries-to-pattern" class="tracking-section">
				<hr class="whitespace" style="height: 30vh;" />

				<h2> And now, decision trees </h2>
				<p> Finding patterns in data is where machine learning comes in.  </p>
				<p> One example of a machine learning method is a <strong>decision tree</strong>. Decision trees look at one variable at a time and are a reasonably accessible (though rudimentary) machine learning method. </p>
				</div>

				<hr class="whitespace" style="height: 30vh;" />
			</div>
		</div>
	</div>
	<div class="row" id="split">
		<div class="col-xs-4 col-xs-push-8">
			<div id="elevation-to-histogram" class="tracking-section">
				<hr class="whitespace" style="height: 20vh;" />
				<h2> Finding better boundaries </h2>
				<p> Let's revisit the 73-m (239.5 ft) elevation boundary proposed previously to see how we can improve upon our intuition. </p>
				<p> Clearly, this requires a different perspective.  </p>
				<hr class="whitespace" style="height: 40vh;" />
				<p> By transforming our visualization into a <strong>histogram</strong>, we can better see how frequently homes appear at each elevation. </p>
				<p> While the highest home in New York is 73m, the majority of them seem to have far lower elevations. </p>

			</div>
			<div id="introduce-split" class="tracking-section">
				<hr class="whitespace" style="height: 30vh;" />
				<h2>Your first fork</h2>
				<p> A decision tree uses if-then statements to define patterns in data. </p>
				<p> For example, <strong>if</strong> a home's elevation is above some number, <strong>then</strong> the home is probably in San Francisco. </p>

			</div>
			<div id="explain-gini" class="tracking-section">
				<hr class="whitespace" style="height: 30vh;" />
				<p> In machine learning, these statements are called <strong>forks</strong>, and they split the data into two <strong>branches</strong> based on some value. </p>
				<p> That value between the branches is called a <strong>split point</strong>. Homes to the left of that point get categorized in one way, while those to the right are categorized in another. A split point is the decision tree's version of a boundary. </p>

				<hr class="whitespace" style="height: 50vh;" />
				<h2>Tradeoffs</h2>
				<p> Picking a split point has tradeoffs. Our initial split (~73 m) incorrectly classifies some San Francisco homes as New York ones. </p>
				<p> Look at that large slice of green in the left pie chart, those are all the San Francisco homes that are misclassified. These are called <strong>false negatives</strong>. </p>

				<hr class="whitespace" style="height: 50vh;" />
				<p> However, a split point meant to capture every San Francisco home will include many New York homes as well. These are called <strong>false&nbsp;positives</strong>. </p>
				<hr class="whitespace" style="height: 50vh;" />

				<h2>The best split</h2>
				<p> At the <strong>best split</strong>, the results of each branch should be as homogeneous (or pure) as possible. There are several mathematical methods you can choose between to calculate the best split.<span class="footnote-anchor"></span></p>
				<hr class="whitespace" style="height: 20vh;" />
				<p>As we see here, even the best split on a single feature does not fully separate the San Francisco homes from the New York ones.</p>
				<hr class="whitespace" style="height: 10vh;" />
			</div>
			<div id="further-split" class="tracking-section">
				<hr class="whitespace" style="height: 30vh;" />
				<h2>Recursion</h2>
				<p>To add another split point, the algorithm repeats the process above on the subsets of data. This repetition is called <strong>recursion</strong>, and it is a concept that appears frequently in training models.<span class="footnote-anchor"></span></p>

				<p class="small">The histograms to the left show the distribution of each subset, repeated for each variable.</p>
				<hr class="whitespace" style="height: 30vh;" />
				<p>The best split will vary based which branch of the tree you are looking at.<span class="footnote-anchor"></span></p> 
				<p>For lower elevation homes, price per square foot is, at $1061 per sqft, is the best variable for the next if-then statement. For higher elevation homes, it is price, at $514,500</p>.

				<hr class="whitespace" style="height: 40vh;" />
			</div>

		</div>
	</div>
	<div class="row" id="tree">
		<div class="col-xs-4">
			<div class="growing-the-tree" class="tracking-section">
				<hr class="whitespace" style="height: 30vh;" />
				<h2>Growing a tree</h2>
				<p>Additional forks will add new information that can increase a tree's <strong>prediction accuracy</strong>.</p>
				<hr class="whitespace" style="height: 40vh;" />
				<p>Splitting one layer deeper, the tree's accuracy improves to <strong>84%</strong>.</p>
				<hr class="whitespace" style="height: 60vh;" />
				<p>Adding several more layers, we get to <strong>96%</strong>.</p>
				<hr class="whitespace" style="height: 60vh;" />
				<p>You could even continue to add branches until the tree's predictions are <strong>100% accurate</strong>, so that at the end of every branch, the homes are purely in San Francisco or purely in New York.</p>

			</div>
			<div class="leaf-nodes" class="tracking-section">
				<hr class="whitespace" style="height: 60vh;" />
				<p>These ultimate branches of the tree are called <strong>leaf nodes</strong>. Our decision tree models will classify the homes in each leaf node according to which class of homes is in the majority.</p>
				<hr class="whitespace" style="height: 30vh;" />
			</div>

		</div>
	</div>
	<div class="row" id="test">
		<div class="col-xs-4">
			<div id="classify-training-data" class="tracking-section">
				<hr class="whitespace" style="height: 35vh;" />
				<h2>Making predictions</h2>
				<p>The newly-trained decision tree model determines whether a home is in San Francisco or New York by running each data point through the branches.</p>
				<hr class="whitespace" style="height: 35vh;"/>
				<p>Here you can see the data that was used to train the tree flow through the tree.</p>

				<p>This data is called <strong>training data</strong> because it was used to train the model.</p>

				<hr class="whitespace" style="height: 35vh;" />
				<p>Because we grew the tree until it was 100% accurate, this tree maps each training data point perfectly to which city it is in.</p>

			</div>
			<div id="classify-test-data" class="tracking-section">
				<hr class="whitespace" style="height: 40vh;" />
				<h2>Reality check</h2>
				<p>Of course, what matters more is how the tree performs on previously-unseen data.</p>
				<hr class="whitespace" style="height: 40vh;" />
				<p>To <strong>test</strong> the tree's performance on new data, we need to apply it to data points that it has never seen before. This previously unused data is called <strong>test data</strong>.</p>
				<hr class="whitespace" style="height: 40vh;" />
				<p>Ideally, the tree should perform similarly on both known and unknown data.</p>
				<hr class="whitespace" style="height: 25vh;" />
				<p>So this one is less than ideal.<span class="footnote-anchor"></span></p>
				<hr class="whitespace" style="height: 25vh;" />

			</div>
			<div id="misclassification" class="tracking-section">

				<p>These errors are due to <strong>overfitting</strong>. Our model has learned to treat every detail in the training data as important, even details that turned out to be irrelevant.</p>

				<p>Overfitting is part of a fundamental concept in many machine learning models as we have seen before.<span class="footnote-anchor"></span></p>
				<hr class="whitespace" style="height: 30vh;" />
			</div>
		</div>
	</div>
	<div id="conclusion" class="tracking-section">
		<div class="row">
			<div class="col-xs-8 col-xs-offset-2">
				<hr class="whitespace" style="height: 10vh;" />
				<hr class="whitespace" style="height: 25vh;" />
			</div>
		</div>


		<div class="row" id="footnotes">
			<div class="col-xs-8">
				<h3>Footnotes</h3>
				<ol id="footnote-list">
					<li>To learn more about calculating the optimal split, search for 'gini index' or 'cross entropy'</li>
					<li>One reason computers are so good at applying statistical learning techniques is that they're able to do repetitive tasks, very quickly and without getting bored.</li>
					<li>The algorithm described here is <em>greedy</em>, because it takes a top-down approach to splitting the data. In other words, it is looking for the variable that makes each subset the most homogeneous <em>at that moment</em>.</li>
					<li>Hover over the dots to see the path it took in the tree.</li>
					<li>Spoiler alert: It's the bias/variance tradeoff!</li>

				</ol>
			</div>
		</div>
	</div>

</div>

<div class="static-container" id="shadow-scatterplot"></div>
<div class="static-container" id="intro-scatterplot"></div>
<div class="static-container" id="split-quality"></div>
<div class="static-container" id="decision-tree"></div>
<div class="static-container" id="train-vs-test"></div>

<div id="resolution-disclaimer">
  <div id="disclaimer-wrapper">
    <p>We are so sorry, but we designed this site for desktop
    rather than mobile viewing. Please come back on
    a desktop (or a screen at least 1024 by 768 pixels in size)!</p>
    <p id="dismiss-disclaimer">&hellip;or go ahead anyway.</p>
  </div>
</div>

    <div id="footer" class="tracking-section">
      <div class="container">
  <div id="footer-content" class="row">
    <div id="about-r2d3" class="col-xs-12 col-sm-5">
      <div class="row">
        <div class="col-xs-3">
          <a id="footer-logo" class="hide-text" href="http://www.r2d3.us/">R2D3</a>
        </div>
        <div class="col-xs-9">
          <p>Source: R2D3 is an experiment in expressing statistical thinking with interactive design. 
          <p>More Information? Check out their <a href="http://www.r2d3.us/">Website</a>.</p>
        </div>
      </div>
    </div>
  </div>
</div>
    </div>


<script type="text/javascript" src="http://www.r2d3.us/static/dist/c814f45e5cce5d96ddf550688fefd942.js"></script>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-56084033-1', 'auto');
  ga('send', 'pageview');
</script>
    
<script src="http://www.r2d3.us/static/pages/decision-trees-part-1/housing-data/tree-training-set-98.js"></script>
<script type="text/javascript" src="http://www.r2d3.us/static/dist/24a2beb93032441d9bd16ce805264f95.js"></script>

  </body>
</html>