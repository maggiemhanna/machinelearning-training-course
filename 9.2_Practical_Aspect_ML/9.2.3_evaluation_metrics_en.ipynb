{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.item {\n",
       "    vertical-align: bottom;\n",
       "    text-align: center;\n",
       "}\n",
       "img {\n",
       "    background-color: white;\n",
       "}\n",
       ".caption {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       "/* Three image containers (use 25% for four, and 50% for two, etc) */\n",
       ".column {\n",
       "  float: left;\n",
       "  width: 50%;\n",
       "  padding: 5px;\n",
       "}\n",
       "\n",
       "/* Clear floats after image containers */\n",
       ".row::after {\n",
       "  content: \"\";\n",
       "  clear: both;\n",
       "  display: table;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "utils.set_css_style('style.css')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation Metrics\n",
    "\n",
    "Choosing the right metric is crucial while evaluating machine learning (ML) models. Various metrics are proposed to evaluate ML models in different applications. In some applications looking at a single metric may not give you the whole picture of the problem you are solving, and you may want to use a subset of the metrics discussed in this post to have a concrete evaluation of your models.\n",
    "\n",
    "Whether you're tuning hyperparameters, or trying out different ideas for learning algorithms, or just trying out different options for building your machine learning system. You'll find that your progress will be much faster if you have a single real number evaluation metric that lets you quickly rank ideas and hyperparameters. Therefore, for a successful machine learning project, setting up a single real number evaluation metric is a key. \n",
    "\n",
    "Applied machine learning is a very empirical process. We often have an idea, code it up, run the experiment to see how it did, and then use the outcome of the experiment to refine the ideas. And then keep going around this loop as you keep on improving your algorithm.\n",
    "\n",
    "<img src=\"figures/ml-idea-iteration.png\" alt=\"ml-idea-iteration\" style=\"width: 400px;\"/>\n",
    "\n",
    "Nevertheless, sometimes it's not always easy to combine all the things you care about into a single evaluation metric. In those cases, it is sometimes useful to set up **satisficing matrics** as well as the **optimizing matric**. \n",
    "\n",
    "As a side note, it is also worth mentioning that the evaluation metric is different from loss function. Loss functions are functions that show a measure of the model performance and are used to train a machine learning model (using some kind of optimization), and are usually differentiable in model’s parameters. On the other hand, metrics are used to monitor and measure the performance of a model (during training, and test), and do not need to be differentiable. However if for some tasks the performance metric is differentiable, it can be used both as a loss function (perhaps with some regularizations added to it), and a evaluation metric, such as MSE.\n",
    "\n",
    "Metrics can be grouped into different categories based on the ML model/application they are mostly used for:\n",
    "\n",
    "* Classification Metrics (accuracy, precision, recall, F1-score, ROC, AUC, …)\n",
    "* Regression Metrics (MSE, MAE)\n",
    "* Statistical Metrics (Correlation)\n",
    "* Computer Vision Metrics (PSNR, SSIM, IoU)\n",
    "* NLP Metrics (Perplexity, BLEU score)\n",
    "* Deep Learning Related Metrics (Inception score, Frechet Inception distance)\n",
    "\n",
    "Here we will focus on classification and regression metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Regression related metrics\n",
    "\n",
    "\n",
    "Regression models are another family of machine learning and statistical models, which are used to predict a continuous target values³. They have a wide range of applications, from house price prediction, E-commerce pricing systems, weather forecasting, stock market prediction, to image super resolution, feature learning via auto-encoders, and image compression.\n",
    "\n",
    "Metrics used to evaluate these models should be able to work on a set of continuous values (with infinite cardinality), and are therefore slightly different from classification metrics.\n",
    "\n",
    "\n",
    "### 3.1.1. MSE\n",
    "\n",
    "“Mean squared error” is perhaps the most popular metric used for regression problems. It essentially finds the average squared error between the predicted and actual values.\n",
    "\n",
    "Let’s assume we have a regression model which predicts the price of houses in Seattle area (denoted by $\\hat{y}_i$ ), and let’s say for each house we also have the actual price the house was sold for (denoted by $y_i$). Then the MSE can be calculated as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{MSE} = \\frac{1}{m} \\sum_i^m (\\hat{y}_i - y_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "Where $m$ is the number of observations. The use of square distance allow us to penalize the large distances extremely.\n",
    "\n",
    "<img src=\"figures/mse.jpg\" alt=\"mse\" style=\"width: 500px;\"/>\n",
    "\n",
    "### 3.1.2. RMSE \n",
    "\n",
    "**RMSE** is just the square root of MSE. The square root is introduced to make scale of the errors to be the same as the scale of targets.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{RMSE} = \\sqrt{\\frac{1}{m} \\sum_i^m (\\hat{y}_i - y_i)^2}\n",
    "\\end{equation}\n",
    "\n",
    "Looking at house pricing prediction, RMSE essentially shows what is the average deviation in your model predicted house prices in dollars (same unit) from the target values (the prices the houses are sold for).\n",
    "\n",
    "\n",
    "### 3.1.3. MAE\n",
    "\n",
    "Mean absolute error (or mean absolute deviation) is another metric which finds the average absolute distance between the predicted and target values. MAE is define as below:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{MAE} = \\frac{1}{m} \\sum_i^m |\\hat{y}_i - y_i|\n",
    "\\end{equation}\n",
    "\n",
    "MAE is known to be more robust to the outliers than MSE. The main reason being that in MSE by squaring the errors, the outliers (which usually have higher errors than other samples) get more attention and dominance in the final error and impacting the model parameters.\n",
    "\n",
    "### 3.1.4. R-Squared\n",
    "\n",
    "R Squared is a measurement that tells you to what extent the proportion of variance in the dependent variable (target) is explained by the variance in the predictor variables. In simpler terms, while the coefficients estimate trends, R-squared represents the scatter around the line of best fit.\n",
    "\n",
    "For example, if the R² is 0.80, then 80% of the variation can be explained by the model’s inputs.\n",
    "If the R² is 1.0 or 100%, that means that all movements of the dependent variable can be entirely explained by the movements of the independent variables.\n",
    "To show a visual example, despite having the same line of best fit, the R² on the right is much higher than the one on the left.\n",
    "\n",
    "<img src=\"figures/r-squared.png\" alt=\"r-squared\" style=\"width: 800px;\"/>\n",
    "\n",
    "The equation for R² is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{R^2} = 1 - \\frac{\\mathsf{Explained\\ Variation}}{\\mathsf{Total\\ Variation}}\n",
    "\\end{equation}\n",
    "\n",
    "The Explained Variation is equal to the sum of squared residuals while the total variation is equal to the total sum of squared.\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathsf{SS_{residual}} = \\sum_{i=0}^{m} (y_i  -  \\hat{y}_i)^2  \\\\\n",
    "\\mathsf{SS_{total}} = \\sum_{i=0}^{m} (y_i  -  \\bar{y}_i)^2\n",
    "\\end{align*}\n",
    "\n",
    "###  3.1.5. Adjusted R-Squared\n",
    "\n",
    "Every additional independent variable added to a model always increases the R² value — therefore, a model with several independent variables may seem to be a better fit even if it isn’t. This is where Adjusted R² comes in. The adjusted R² compensates for each additional independent variable and only increases if the new term improves the model more than would be expected by chance.\n",
    "\n",
    "\n",
    "The formula for the Adjusted R-Squared taking into consideration the number of predictors $p$ of the model is then:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{R^2_{adjusted}} = 1 - \\frac{(1 - \\mathsf{R^2})(m-1)}{m-p-1}\n",
    "\\end{equation}\n",
    "\n",
    "While values are usually positive, they can be negative as well. This could happen if your $R^2$ is zero; After the adjustment, the value can dip below zero. This usually indicates that your model is a poor fit for your data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Regression metrics with python\n",
    "\n",
    "Let's consider the same diabetes example we have seen before. We will load our dataset, split it into a training and a testing sets. We will then fit and Linear Regression model and evaluate its performance over the training and the testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s load in the diabetes dataset, turn it into a data frame and define the columns’ names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (442, 10) (442,)\n"
     ]
    }
   ],
   "source": [
    "# Load the Diabetes dataset\n",
    "columns = [\"age\",\"sex\",\"bmi\",\"map\",\"tc\",\"ldl\",\"hdl\",\"tch\",\"ltg\",\"glu\"] # columns names\n",
    "diabetes = datasets.load_diabetes() # Call the diabetes dataset from sklearn\n",
    "df = pd.DataFrame(diabetes.data, columns=columns) # load the dataset as a pandas data frame\n",
    "y = diabetes.target # define the target variable (dependent variable) as y\n",
    "print(\"Dataset shape: \", df.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `train_test_split` function in order to make the split. The `test_size=0.2` inside the function indicates the percentage of the data that should be held over for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (353, 10) (353,)\n",
      "Testing set:  (89, 10) (89,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
    "print(\"Training set: \", X_train.shape, y_train.shape)\n",
    "print(\"Testing set: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Linear Regression model\n",
    "model_lin = LinearRegression(normalize=True)\n",
    "# Fitting Linear Regression model over the training set\n",
    "model_lin.fit(X_train, y_train)\n",
    "\n",
    "# predicting over training & testing datasets\n",
    "y_train_pred = model_lin.predict(X_train)\n",
    "y_test_pred = model_lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model over both sets using `sklearn.metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "MSE is 2877.1863682742664\n",
      "RMSE is 53.63941058843084\n",
      "MAE is 42.996280499750384\n",
      "R2 score is 0.5137499253152344\n",
      "\n",
      "\n",
      "The model performance for training set\n",
      "--------------------------------------\n",
      "MSE is 2821.8637175436693\n",
      "RMSE is 53.121217206909606\n",
      "MAE is 44.947255573196266\n",
      "R2 score is 0.5250886176863195\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation for training set\n",
    "mse_train = metrics.mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = (np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "mae_train = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('MSE is {}'.format(mse_train))\n",
    "print('RMSE is {}'.format(rmse_train))\n",
    "print('MAE is {}'.format(mae_train))\n",
    "print('R2 score is {}'.format(r2_train))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "mse_test = metrics.mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = (np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "mae_test = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = metrics.r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('MSE is {}'.format(mse_test))\n",
    "print('RMSE is {}'.format(rmse_test))\n",
    "print('MAE is {}'.format(mae_test))\n",
    "print('R2 score is {}'.format(r2_test))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Classification related metrics\n",
    "\n",
    "Classification is one of the most widely used problems in machine learning with various industrial applications, from face recognition, Youtube video categorization, content moderation, medical diagnosis, to text classification, hate speech detection on Twitter.\n",
    "\n",
    "There are various ways to evaluate a classification model, in this section we'll be covering some of the most popular ones below.\n",
    "\n",
    "### 3.3.1. Confusion Matrix (not a metric, but important to know!)\n",
    "\n",
    "One of the key concept in classification performance is the confusion matrix, which is a tabular visualization of the model predictions versus the ground-truth labels. Each row of confusion matrix represents the instances in a predicted class and each column represents the instances in an actual class.\n",
    "\n",
    "Let’s go through this with an example. Let’s assume we are building a binary classification to classify cat images from non-cat images. And let’s assume our test set has 1100 images (1000 non-cat images, and 100 cat images), with the below confusion matrix.\n",
    "\n",
    "<img src=\"figures/cats-cm.png\" alt=\"cats-cm\" style=\"width: 500px;\"/>\n",
    "\n",
    "* Out of 100 cat images the model has predicted 90 of them correctly and has mis-classified 10 of them. If we refer to the “cat” class as positive and the non-cat class as negative class, then 90 samples predicted as cat are considered as as true positive (TP), and the 10 samples predicted as non-cat are false negative (FN).\n",
    "\n",
    "* Out of 1000 non-cat images, the model has classified 940 of them correctly, and mis-classified 60 of them. The 940 correctly classified samples are referred as true negative (TN), and those 60 are referred as false positive (FP).\n",
    "\n",
    "As we can see diagonal elements of this matrix denote the correct prediction for different classes, while the off-diagonal elements denote the samples which are mis-classified.\n",
    "\n",
    "Below is a more general representation of the confusion matrix:\n",
    "\n",
    "<img src=\"figures/confusion-matrix.png\" alt=\"confusion-matrix\" style=\"width: 500px;\"/>\n",
    "\n",
    "Now that we have a better understanding of the confusion matrix, let’s get into the actual metrics.\n",
    "\n",
    "### 3.3.2. Classification Accuracy\n",
    "\n",
    "Classification accuracy is perhaps the simplest metrics one can imagine, and is defined as the number of correct predictions divided by the total number of predictions. \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} \n",
    "\\end{equation}\n",
    "\n",
    "So in the above example, out of 1100 samples 1030 are predicted correctly, resulting in a classification accuracy of:\n",
    "\n",
    "**Classification accuracy**= (90+940)/(1000+100)= 1030/1100= 93.6%\n",
    "\n",
    "\n",
    "### 3.3.3. Precision\n",
    "\n",
    "There are many cases in which classification accuracy is not a good indicator of your model performance. One of these scenarios is when your class distribution is imbalanced (one class is more frequent than others). In this case, even if you predict all samples as the most frequent class you would get a high accuracy rate, which does not make sense at all (because your model is not learning anything, and is just predicting everything as the top class). \n",
    "\n",
    "For example in our cat vs non-cat classification above, if the model predicts all samples as non-cat, it would result in a 1000/1100= 90.9%.\n",
    "\n",
    "Therefore we need to look at class specific performance metrics too. Precision is one of such metrics, which is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{Precision} = \\frac{TP}{TP + FP} \n",
    "\\end{equation}\n",
    "\n",
    "**The precision of the model is interpreted as follows: out of those positively predicted, what is the percentage of observations that are actually positive**.\n",
    "\n",
    "The precision of Cat and Non-Cat class in the above example can be calculated as:\n",
    "\n",
    "**Precision_Cat** = #samples correctly predicted cat/#samples predicted as cat = 90 / (90 + 60) = 60%\n",
    "\n",
    "**Precision_NonCat** = 940 / 950 = 98.9%\n",
    "\n",
    "As we can see the model has much higher precision in predicting non-cat samples, versus cats. This is not surprising, as model has seen more examples of non-cat images during training, making it better in classifying that class.\n",
    "\n",
    "\n",
    "###  3.3.4. Recall \n",
    "\n",
    "Recall is another important metric, which is defined as the fraction of samples from a class which are correctly predicted by the model. More formally:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{Recall} = \\frac{TP}{TP + FN} \n",
    "\\end{equation}\n",
    "\n",
    "Therefore, for our example above, the recall rate of cat and non-cat classes can be found as:\n",
    "\n",
    "**Recall_Cat** = 90 / 100 = 90%\n",
    "\n",
    "**Recall_NonCat** = 940 / 1000 = 94%\n",
    "\n",
    "### 3.3.5. F1 Score\n",
    "\n",
    "Depending on application, you may want to give higher priority to recall or precision. But there are many applications in which both recall and precision are important. Therefore, it is natural to think of a way to combine these two into a single metric. One popular metric which combines precision and recall is called F1-score, which is the harmonic mean of precision and recall defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{F1score} = 2*\\frac{\\mathsf{Precision} \\cdot \\mathsf{Recall}}{\\mathsf{Precision}+\\mathsf{Recall}} \n",
    "\\end{equation}\n",
    "\n",
    "#### Why is the F-Measure a harmonic mean and not an arithmetic mean of the Precision and Recall measures?\n",
    "\n",
    "This is just for a quick reference to understand the nature of the arithmetic mean and the harmonic mean with plots. As you can see from the plot, consider the X axis and Y axis as precision and recall, and the Z axis as the F1 Score. So, from the plot of the harmonic mean, both the precision and recall should contribute evenly for the F1 score to rise up unlike the Arithmetic mean.\n",
    "\n",
    "This is for the arithmetic mean.\n",
    "\n",
    "<img src=\"figures/arithmetic-mean.jpg\" alt=\"arithmetic-mean\" style=\"width: 300px;\"/>\n",
    "\n",
    "This is for the harmonic mean.\n",
    "\n",
    "<img src=\"figures/harmonic-mean.jpg\" alt=\"harmonic-mean\" style=\"width: 300px;\"/>\n",
    "\n",
    "So for our cat classification example, the F1-score can be calculated as:\n",
    "\n",
    "**F1-score**= 2 * 0.6 * 0.9  / (0.6 + 0.9) = 72%\n",
    "\n",
    "The generalized version of F-score is defined as below. As we can see F1-score is special case of $F_{\\beta }$ when $\\beta= 1$, where $\\beta$ is chosen such that recall is considered $\\beta$ times as important as precision.\n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle F_{\\beta }=(1+\\beta ^{2})\\cdot {\\frac {\\mathsf {Precision} \\cdot \\mathsf {Recall} }{(\\beta ^{2}\\cdot \\mathsf {Precision} )+\\mathsf {Recall} }}}\n",
    "\\end{equation}\n",
    "\n",
    "It is good to mention that there is always a trade-off between precision and recall of a model, if you want to make the precision too high, you would end up seeing a drop in the recall rate, and vice versa.\n",
    "\n",
    "### 3.3.6. Sensitivity and Specificity\n",
    "\n",
    "Sensitivity and specificity are two other popular metrics mostly used in medical and biology related fields, and are defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle \\mathsf{Sensitivity} = \\mathsf{Recall} = \\frac{TP}{TP+FN} }\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{Specificity} = \\mathsf{True \\ Negative \\ Rate} = \\frac{TN}{TN+FP}\n",
    "\\end{equation}\n",
    "\n",
    "### 3.3.7. Receiver Operating Characteristic Curve\n",
    "\n",
    "The receiver operating characteristic (ROC) curve is plot which shows the performance of a binary classifier as function of its cut-off threshold. It essentially shows the true positive rate (TPR) against the false positive rate (FPR) for various threshold values. Let’s explain more.\n",
    "Many of the classification models are probabilistic, i.e. they predict the probability of a sample being a cat. They then compare that output probability with some cut-off threshold and if it is larger than the threshold they predict its label as cat, otherwise as non-cat. As an example your model may predict the below probabilities for 4 sample images: [0.45, 0.6, 0.7, 0.3]. Then depending on the threshold values below, you will get different labels:\n",
    "\n",
    "* cut-off= 0.5: predicted-labels= [0,1,1,0] (default threshold)\n",
    "* cut-off= 0.2: predicted-labels= [1,1,1,1]\n",
    "* cut-off= 0.8: predicted-labels= [0,0,0,0]\n",
    "\n",
    "As you can see by varying the threshold values, we will get completely different labels. And as you can imagine each of these scenarios would result in a different precision and recall (as well as TPR, FPR) rates.\n",
    "\n",
    "ROC curve essentially finds out the TPR and FPR for various threshold values and plots TPR against the FPR. A sample ROC curve is shown in Figure below.\n",
    "\n",
    "<img src=\"figures/roc-curve.png\" alt=\"roc-curve\" style=\"width: 500px;\"/>\n",
    "\n",
    "As we can see from this example, the lower the cut-off threshold on positive class, the more samples predicted as positive class, i.e. higher true positive rate (recall) and also higher false positive rate (corresponding to the right side of this curve). Therefore, there is a trade-off between how high the recall could be versus how much we want to bound the error (FPR).\n",
    "ROC curve is a popular curve to look at overall model performance and pick a good cut-off threshold for the model.\n",
    "\n",
    "### 3.3.8. AUC\n",
    "\n",
    "The area under the curve (AUC), is an aggregated measure of performance of a binary classifier on all possible threshold values (and therefore it is threshold invariant).\n",
    "\n",
    "AUC calculates the area under the ROC curve, and therefore it is between 0 and 1. **One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example**.\n",
    "\n",
    "<img src=\"figures/AUC.png\" alt=\"AUC\" style=\"width: 400px;\"/>\n",
    "\n",
    "On high-level, the higher the AUC of a model the better it is. But sometimes threshold independent measure is not what you want, e.g. you may care about your model recall and require that to be higher than 99% (while it has a reasonable precision or FPR). In that case, you may want to tune your model threshold such that it meets your minimum requirement on those metrics (and you may not care if you model AUC is not too high).\n",
    "\n",
    "Therefore in order to decide how to evaluate your classification model performance, perhaps you want to have a good understanding of the business/problem requirement and the impact of low recall vs. low precision, and decide what metric to optimize for.\n",
    "\n",
    "From a practical standpoint, a classification model which outputs probabilities is preferred over a single label output, as it provides the flexibility of tuning the threshold such that it meets your minimum recall/precision requirements. Not all models provide this nice probabilistic outputs though, e.g. SVM does not provide a simple probability as an output (although it provides margin which can be used to tune the decision, but it is not as straightforward and interpretable as having output probabilities)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Classification metrics with python\n",
    "\n",
    "In the proceeding example, we’ll take a look at all the metrics in action. For simplicity, we’ll be using one of the datasets provided by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the breast cancer dataset, and explore available features and target. The breast cancer dataset is a classic and very easy binary classification dataset. The objective of our model is to predict whether a patient has breast cancer or not given the available features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()\n",
    "\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare our data for training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll be using the logistic regression classifier but any classification algorithm will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train, y_train)\n",
    "y_test_pred = lgr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 58,   5],\n",
       "       [  6, 102]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` also offers a nice function to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x12a64b750>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_confusion_matrix(lgr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Accuracy of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935672514619883"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "The recall of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92063492, 0.94444444])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test, y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "The precision of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90625   , 0.95327103])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test, y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1score\n",
    "\n",
    "The f1score of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91338583, 0.94883721])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic - AUC\n",
    "\n",
    "In able to plot ROC or evaluate AUC, we need the probability outputs of our model instead of the final prediction.\n",
    "\n",
    "We call the `predict_proba` method rather than `predict` in order to obtain a list of probabilities which represent the likelihood that a sample falls under a given category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = lgr.predict_proba(X_test)\n",
    "malignant_probs = probs[:,1]\n",
    "\n",
    "# calculating roc arguments\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, malignant_probs)\n",
    "# calculating auc\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,8])\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'y', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfa-venv",
   "language": "python",
   "name": "pfa-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
