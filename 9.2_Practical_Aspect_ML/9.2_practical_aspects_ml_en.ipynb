{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.item {\n",
       "    vertical-align: bottom;\n",
       "    text-align: center;\n",
       "}\n",
       "img {\n",
       "    background-color: white;\n",
       "}\n",
       ".caption {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       "/* Three image containers (use 25% for four, and 50% for two, etc) */\n",
       ".column {\n",
       "  float: left;\n",
       "  width: 50%;\n",
       "  padding: 5px;\n",
       "}\n",
       "\n",
       "/* Clear floats after image containers */\n",
       ".row::after {\n",
       "  content: \"\";\n",
       "  clear: both;\n",
       "  display: table;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "utils.set_css_style('style.css')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Splitting\n",
    "\n",
    "## 1.1. Why split the data?\n",
    "\n",
    "To use an analogy, let’s say you teach a child to multiply by letting the kid train on the small multiplication table, i.e. everything from 1x1 to 9x9.\n",
    "\n",
    "Next, you test whether the kid is able to perform the same multiplications. The result is a success. The kid gets it right almost every time.\n",
    "\n",
    "<img src=\"figures/multiplication.jpeg\" alt=\"multiplication\" style=\"width: 300px;\"/>\n",
    "\n",
    "What’s the problem here?\n",
    "\n",
    "You don’t know if the kid understands multiplication at all, or has simply memorized the table!\n",
    "\n",
    "So what you would do instead is test the kid on multiplications like 11x12, that are outside of the table.\n",
    "\n",
    "This is exactly why we need to test machine learning models on unseen data. Otherwise, we have no way of knowing whether the algorithm has learned a generalizable pattern or has simply memorized the training data.\n",
    "\n",
    "## 1.2. Training, validation & test datasets\n",
    "\n",
    "Data splits usually depends on the use case. But typically, we split data into 3 main datasets:\n",
    "\n",
    "* Training dataset\n",
    "* Validation dataset\n",
    "* Testing dataset\n",
    "\n",
    "<img src=\"figures/splits.png\" alt=\"splits\" style=\"width: 500px;\"/>\n",
    "\n",
    "Let's quote the base definitions from Jason Brownlee’s excellent article on this topic, as it is quite comprehensive:\n",
    "\n",
    "### 1.2.1. Training dataset\n",
    "\n",
    "> Training Dataset: The sample of data used to fit the model.\n",
    "\n",
    "The actual dataset that we use to train the model (weights and biases in the case of Neural Network). The model sees and learns from this data.\n",
    "\n",
    "\n",
    "### 1.2.2. Validation dataset\n",
    "\n",
    "> Validation Dataset: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration.\n",
    "\n",
    "The validation set is used to evaluate a given model, but this is for frequent evaluation. We as machine learning engineers use this data to fine-tune the model hyperparameters. Hence the model occasionally sees this data, but never does it “Learn” from this. We use the validation set results and update higher level hyperparameters. So the validation set in a way affects a model, but indirectly.\n",
    "\n",
    "### 1.2.3. Test dataset\n",
    "\n",
    "> Test Dataset: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
    "\n",
    "The Test dataset provides the gold standard used to evaluate the model. It is only used once a model is completely trained (using the train and validation sets). The test set is generally what is used to evaluate competing models (For example on many Kaggle competitions, the validation set is released initially along with the training set and the actual test set is only released when the competition is about to close, and it is the result of the the model on the Test set that decides the winner). Many a times the validation set is used as the test set, but it is not good practice. The test set is generally well curated. It contains carefully sampled data that spans the various classes that the model would face, when used in the real world.\n",
    "\n",
    "### 1.2.4. Dataset split ratio\n",
    "\n",
    "This mainly depends on 2 things. First, the total number of samples in your data and second, on the actual model you are training.\n",
    "\n",
    "Some models need substantial data to train upon, so in this case you would optimize for the larger training sets. Models with very few hyperparameters will be easy to validate and tune, so you can probably reduce the size of your validation set, but if your model has many hyperparameters, you would want to have a large validation set as well(although you should also consider cross validation). Also, if you happen to have a model with no hyperparameters or ones that cannot be easily tuned, you probably don’t need a validation set too!\n",
    "\n",
    "Like many other things in machine learning, the train-test-validation split ratio is also quite specific to your use case and it gets easier to make judge ment as you train and build more and more models.\n",
    "\n",
    "\n",
    "## 1.3. Cross-validation\n",
    "\n",
    "When there is never enough data to train your model, removing a part of it for validation poses a problem of underfitting. By reducing the training data, we risk losing important patterns/ trends in data set, which in turn increases error induced by bias. So, what we require is a method that provides ample data for training the model and also leaves ample data for validation. Cross validation does exactly that.\n",
    "\n",
    "### 1.3.1. K-fold cross validation\n",
    "\n",
    "In K Fold cross validation, the data is divided into k subsets. Now the holdout method is repeated k times, such that each time, one of the k subsets is used as the test set/ validation set and the other k-1 subsets are put together to form a training set. The error estimation is averaged over all k trials to get total effectiveness of our model. As can be seen, every data point gets to be in a validation set exactly once, and gets to be in a training set k-1 times. This significantly reduces bias as we are using most of the data for fitting, and also significantly reduces variance as most of the data is also being used in validation set. Interchanging the training and test sets also adds to the effectiveness of this method. As a general rule and empirical evidence, K = 5 or 10 is generally preferred, but nothing’s fixed and it can take any value.\n",
    "\n",
    "<img src=\"figures/cross-validation.png\" alt=\"cross-validation\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "### 1.3.2. Stratified k-fold cross validation\n",
    "\n",
    "In some cases, there may be a large imbalance in the response variables. For example, in dataset concerning price of houses, there might be large number of houses having high price. Or in case of classification, there might be several times more negative samples than positive samples. For such problems, a slight variation in the K Fold cross validation technique is made, such that each fold contains approximately the same percentage of samples of each target class as the complete set, or in case of regression problems, the mean response value is approximately equal in all the folds. This variation is also known as Stratified K Fold.\n",
    "\n",
    "These validation techniques are also referred to as Non-exhaustive cross validation methods. These do not compute all ways of splitting the original sample. Exhaustive Methods, on the other hand, compute all possible ways the data can be split into training and test sets.\n",
    "\n",
    "### 1.3.3. Leave-P-Out cross validation\n",
    "\n",
    "This approach leaves p data points out of training data, i.e. if there are n data points in the original sample then, n-p samples are used to train the model and p points are used as the validation set. This is repeated for all combinations in which original sample can be separated this way, and then the error is averaged for all trials, to give overall effectiveness.\n",
    "\n",
    "This method is exhaustive in the sense that it needs to train and validate the model for all possible combinations, and for moderately large p, it can become computationally infeasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Splitting data with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see how to do split a dataset into a training and a testing datasets in Python. We’ll do this using the `scikit-learn` library and specifically the `train_test_split` method. We’ll start with importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s load in the diabetes dataset, turn it into a data frame and define the columns’ names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (442, 10) (442,)\n"
     ]
    }
   ],
   "source": [
    "# Load the Diabetes dataset\n",
    "columns = [\"age\",\"sex\",\"bmi\",\"map\",\"tc\",\"ldl\",\"hdl\",\"tch\",\"ltg\",\"glu\"] # columns names\n",
    "diabetes = datasets.load_diabetes() # Call the diabetes dataset from sklearn\n",
    "df = pd.DataFrame(diabetes.data, columns=columns) # load the dataset as a pandas data frame\n",
    "y = diabetes.target # define the target variable (dependent variable) as y\n",
    "print(\"Dataset shape: \", df.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our features table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>map</th>\n",
       "      <th>tc</th>\n",
       "      <th>ldl</th>\n",
       "      <th>hdl</th>\n",
       "      <th>tch</th>\n",
       "      <th>ltg</th>\n",
       "      <th>glu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi       map        tc       ldl       hdl  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "        tch       ltg       glu  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our target array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 75., 141., 206., 135.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `train_test_split` function in order to make the split. The `test_size=0.2` inside the function indicates the percentage of the data that should be held over for testing. It’s usually around 80/20 or 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (353, 10) (353,)\n",
      "Testing set:  (89, 10) (89,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
    "print(\"Training set: \", X_train.shape, y_train.shape)\n",
    "print(\"Testing set: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bias & Variance\n",
    "\n",
    "Let's look at the following simple example. If you fit a straight line to the data, maybe a simple linear regression, then this is not a very good fit to the data. This is problem of a high bias, we also say that our model is underfitting the data. On the opposite end, if you fit an incredibly complex regressor, maybe a deep neural network, or a neural network with many hidden units, it's possible that you fit the data perfectly, but that doesn't look like a great fit either. So this is called a regressor of high variance and we also say that this model is overfitting the data. A model in between, with a medium level of complexity, fits the data correctly. \n",
    "\n",
    "As mentioned earlier, in machine learning we usually split our data into two subsets: training data and testing data (and sometimes to three: train, validate and test), and fit our model on the train data, in order to make predictions on the test data. When we do that, one of two thing might happen: we overfit our model or we underfit our model. \n",
    "\n",
    "## 2.1. Overfitting\n",
    "\n",
    "**Overfitting** means that model we trained has trained “too well” and is now, well, fit too closely to the training dataset. This is also called a **high variance** problem. This usually happens when the model is too complex (i.e. too many features/variables compared to the number of observations). This model will be very accurate on the training data but will probably be very not accurate on untrained or new data. It is because this model is not generalized and can’t make any inferences on new unseen data, which is, ultimately, what you are trying to do. Basically, when this happens, the model learns the “noise” in the training data instead of the actual relationships between variables in the data.\n",
    "\n",
    "## 2.2. Underfitting\n",
    "\n",
    "In contrast to overfitting, when a model is underfitted, it means that the model does not fit the training data and therefore misses the trends in the data. It also means the model cannot be generalized to new data. As you probably guessed (or figured out!), this is usually the result of a very simple model (not enough predictors/independent variables). It could also happen when, for example, we fit a linear model (like linear regression) to data that is not linear. It almost goes without saying that this model will have poor predictive ability on the training data.\n",
    "\n",
    "<img src=\"figures/bias-variance.png\" alt=\"bias-variance\" style=\"width: 700px;\"/>\n",
    "\n",
    "One way to check if your model is suffering from high bias or high variance is to compare the training error with the validation set error.\n",
    "\n",
    "\n",
    "## 2.3. Bias & variance diagnosis\n",
    "\n",
    "We need to distinguish whether bias or variance is the problem contributing to bad predictions.\n",
    "\n",
    "The training error will tend to decrease as we increase the complexity of the model (for example the degree $d$ of the polynomial of a linear regression model), whereas the validation/test error will tend to decrease as we increase the complexity up to a point, and then it will increase as complexity is increased, forming a convex curve.\n",
    "\n",
    "* **High bias** (underfitting): both $J_{train}(\\theta)$ and $J_{test}(\\theta)$ will be high. Also, $J_{test}(\\theta) \\approx J_{train}(\\theta)$.\n",
    "\n",
    "* **High variance** (overfitting): $J_{train}(\\theta)$ will be low and $J_{test}(\\theta)$ will be much greater than $J_{train}(\\theta)$.\n",
    "\n",
    "The is summarized in the figure below:\n",
    "\n",
    "<img src=\"figures/bias-variance-diagnosis.png\" alt=\"bias-variance-diagnosis\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "## 2.4. Bias & variance correction\n",
    "\n",
    "In the previous section, we saw how looking at training error and validation error can help you diagnose whether your algorithm has a bias or a variance problem, or maybe both. Knowing whether your model is overfitting or underfitting your data helps you take the correct measures in order to improve your algorithms' performance systematically.\n",
    "\n",
    "If your algorithm has a high bias, the following are some of the possible remedies:\n",
    "* Try to make your model more complex\n",
    "* Add more features if possible\n",
    "* Try a different model that is suitable for your data.\n",
    "* Train your model longer.\n",
    "\n",
    "On the other hand, if your algorithm has a high variance, you can:\n",
    "* Get more data.\n",
    "* Use regularization.\n",
    "* Try a different model that is suitable for your data.\n",
    "\n",
    "<img src=\"figures/bias-variance-tradeoff.jpeg\" alt=\"bias-variance\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Regularization\n",
    "\n",
    "Consider the problem of predicting $y$ from $x \\in R$. The left most figure below shows the result of fitting a $y = \\theta_0+\\theta_1 x$ to a dataset. We see that the data doesn’t really lie on straight line, and so the fit is not very good.\n",
    "\n",
    "Instead, if we had added an extra feature $x^2$, and fit $y = \\theta_0 + \\theta_1 x + \\theta_1 x^2$, then we obtain a slightly better fit to the data (See middle figure). Naively, it might seem that the more features we add, the better. However, there is also a danger in adding too many features: The rightmost figure is the result of fitting a 5^{th} order polynomial:\n",
    "\n",
    "\\begin{equation}\n",
    "h_{\\theta}(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 + \\theta_5 x^5  \n",
    "\\end{equation}\n",
    "\n",
    "We see that even though the fitted curve passes through the data perfectly, we would not expect this to be a very good predictor. This is a problem of **overfitting**.\n",
    " \n",
    "<img src=\"figures/reg_example.png\" alt=\"reg-example\" style=\"width: 700px;\"/>\n",
    "  \n",
    "If we have overfitting from our hypothesis function, we can reduce the weight that some of the terms in our function carry by increasing their corresponding cost. Let's suppose we want to reduce the influence of $\\theta_4 x^4$ and $\\theta_5 x^5$. Without actually getting rid of these features or changing the form of our hypothesis, we can instead modify our cost function, and the optimisation problem becomes:\n",
    "  \n",
    "\\begin{equation}\n",
    "\\min_{\\theta} \\dfrac {1}{2m} \\sum _{i=1}^m \\left (h_\\theta (x_{i}) - y_{i} \\right)^2 + 1000 \\times \\theta_4^2 + 1000 \\times \\theta_5^2\n",
    "\\end{equation}\n",
    "\n",
    "The reason we've added two extra terms at the end is to inflate the cost of $\\theta_4$ and $\\theta_5$ in order to reduce the impact of the correponding features. Now, in order for the cost function to get close to zero, we will have to reduce the values of $\\theta_4$ and $\\theta_5$. As a result, we may see that the new hypothesis fits the data better.\n",
    " \n",
    "We could also **regularize** all of our $\\theta$ parameters in a single summation as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{\\theta} \\dfrac {1}{2m} \\sum _{i=1}^m \\left (h_\\theta (x_{i}) - y_{i} \\right)^2 + \\lambda \\sum_{j=1}^n \\theta_j^2\n",
    "\\end{equation}\n",
    "\n",
    " \n",
    "The $\\lambda$, or lambda, is the **regularization parameter**. It determines how much the costs of our $\\theta$ parameters are inflated.\n",
    "\n",
    "Using the above cost function with the extra summation, we can smooth the output of our hypothesis function to reduce overfitting. If $\\lambda$ is chosen to be too large, it may smooth out the function too much and cause underfitting. \n",
    "\n",
    "There are many other regularization techniques, this one is known as the L2 regularization. Other Regularization types include: \n",
    "\n",
    "* Early Stopping\n",
    "* Parameter Norm Penalties \n",
    "    * L1 regularization\n",
    "    * L2 regularization\n",
    "    * Max-norm regularization\n",
    "* Dataset Augmentation\n",
    "* Noise Robustness (Dropout..)\n",
    "* Sparse Representations\n",
    "* ...\n",
    "\n",
    "For more information, you can [check this article](https://medium.com/inveterate-learner/deep-learning-book-chapter-7-regularization-for-deep-learning-937ff261875c)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Learning curves\n",
    "\n",
    "Learning curves are often a very useful thing to plot. If either you wanted to sanity check that your algorithm is working correctly, or if you want to improve the performance of the algorithm.\n",
    "\n",
    "Learning Curve Theory:\n",
    "\n",
    "* Graph that compares the performance of a model on training and testing data over a varying number of training instances\n",
    "* We should generally see performance improve as the number of training points increases\n",
    "* When we separate training and testing sets and graph them individually\n",
    "    * We can get an idea of how well the model can generalize to new data\n",
    "* Learning curve allows us to verify when a model has learned as much as it can about the data, when it occurs\n",
    "    * The performances on the training and testing sets reach a plateau\n",
    "    * There is a consistent gap between the two error rates\n",
    "* The key is to find the sweet spot that minimizes bias and variance by finding the right level of model complexity\n",
    "* Of course with more data any model can improve, and different models may be optimal\n",
    "\n",
    "Types of learning curves:\n",
    "\n",
    "* **Bad Learning Curve: High Bias**\n",
    "    - When training and testing errors converge and are high\n",
    "    - No matter how much data we feed the model, the model cannot represent the underlying relationship and has high systematic errors\n",
    "    - Poor fit\n",
    "    - Poor generalization\n",
    "* **Bad Learning Curve: High Variance**\n",
    "    - When there is a large gap between the errors\n",
    "    - Require data to improve\n",
    "    - Can simplify the model with fewer or less complex features\n",
    "* **Ideal Learning Curve**\n",
    "    - Model that generalizes to new data\n",
    "    - Testing and training learning curves converge at similar values\n",
    "    - Smaller the gap, the better our model generalizes\n",
    "    \n",
    "    \n",
    "The following example is a typical case of high variance:\n",
    "\n",
    "<img src=\"figures/learning-curve-high-variance.jpg\" alt=\"learning-curve-high-variance\" style=\"width: 500px;\"/>\n",
    "\n",
    "The following diagram is a typical case of high bias.\n",
    "\n",
    "<img src=\"figures/learning-curve-high-bias.jpg\" alt=\"learning-curve-high-bias\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation Metrics\n",
    "\n",
    "Choosing the right metric is crucial while evaluating machine learning (ML) models. Various metrics are proposed to evaluate ML models in different applications. In some applications looking at a single metric may not give you the whole picture of the problem you are solving, and you may want to use a subset of the metrics discussed in this post to have a concrete evaluation of your models.\n",
    "\n",
    "Whether you're tuning hyperparameters, or trying out different ideas for learning algorithms, or just trying out different options for building your machine learning system. You'll find that your progress will be much faster if you have a single real number evaluation metric that lets you quickly rank ideas and hyperparameters. Therefore, for a successful machine learning project, setting up a single real number evaluation metric is a key. \n",
    "\n",
    "Applied machine learning is a very empirical process. We often have an idea, code it up, run the experiment to see how it did, and then use the outcome of the experiment to refine the ideas. And then keep going around this loop as you keep on improving your algorithm.\n",
    "\n",
    "<img src=\"figures/ml-idea-iteration.png\" alt=\"ml-idea-iteration\" style=\"width: 400px;\"/>\n",
    "\n",
    "Nevertheless, sometimes it's not always easy to combine all the things you care about into a single evaluation metric. In those cases, it is sometimes useful to set up **satisficing matrics** as well as the **optimizing matric**. \n",
    "\n",
    "As a side note, it is also worth mentioning that the evaluation metric is different from loss function. Loss functions are functions that show a measure of the model performance and are used to train a machine learning model (using some kind of optimization), and are usually differentiable in model’s parameters. On the other hand, metrics are used to monitor and measure the performance of a model (during training, and test), and do not need to be differentiable. However if for some tasks the performance metric is differentiable, it can be used both as a loss function (perhaps with some regularizations added to it), and a evaluation metric, such as MSE.\n",
    "\n",
    "Metrics can be grouped into different categories based on the ML model/application they are mostly used for:\n",
    "\n",
    "* Classification Metrics (accuracy, precision, recall, F1-score, ROC, AUC, …)\n",
    "* Regression Metrics (MSE, MAE)\n",
    "* Statistical Metrics (Correlation)\n",
    "* Computer Vision Metrics (PSNR, SSIM, IoU)\n",
    "* NLP Metrics (Perplexity, BLEU score)\n",
    "* Deep Learning Related Metrics (Inception score, Frechet Inception distance)\n",
    "\n",
    "Here we will focus on classification and regression metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Regression related metrics\n",
    "\n",
    "\n",
    "Regression models are another family of machine learning and statistical models, which are used to predict a continuous target values³. They have a wide range of applications, from house price prediction, E-commerce pricing systems, weather forecasting, stock market prediction, to image super resolution, feature learning via auto-encoders, and image compression.\n",
    "\n",
    "Metrics used to evaluate these models should be able to work on a set of continuous values (with infinite cardinality), and are therefore slightly different from classification metrics.\n",
    "\n",
    "\n",
    "### 3.1.1. MSE\n",
    "\n",
    "“Mean squared error” is perhaps the most popular metric used for regression problems. It essentially finds the average squared error between the predicted and actual values.\n",
    "\n",
    "Let’s assume we have a regression model which predicts the price of houses in Seattle area (denoted by $\\hat{y}_i$ ), and let’s say for each house we also have the actual price the house was sold for (denoted by $y_i$). Then the MSE can be calculated as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{MSE} = \\frac{1}{m} \\sum_i^m (\\hat{y}_i - y_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "Where $m$ is the number of observations. The use of square distance allow us to penalize the large distances extremely.\n",
    "\n",
    "<img src=\"figures/mse.jpg\" alt=\"mse\" style=\"width: 500px;\"/>\n",
    "\n",
    "### 3.1.2. RMSE \n",
    "\n",
    "**RMSE** is just the square root of MSE. The square root is introduced to make scale of the errors to be the same as the scale of targets.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{RMSE} = \\sqrt{\\frac{1}{m} \\sum_i^m (\\hat{y}_i - y_i)^2}\n",
    "\\end{equation}\n",
    "\n",
    "Looking at house pricing prediction, RMSE essentially shows what is the average deviation in your model predicted house prices in dollars (same unit) from the target values (the prices the houses are sold for).\n",
    "\n",
    "\n",
    "### 3.1.3. MAE\n",
    "\n",
    "Mean absolute error (or mean absolute deviation) is another metric which finds the average absolute distance between the predicted and target values. MAE is define as below:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{MAE} = \\frac{1}{m} \\sum_i^m |\\hat{y}_i - y_i|\n",
    "\\end{equation}\n",
    "\n",
    "MAE is known to be more robust to the outliers than MSE. The main reason being that in MSE by squaring the errors, the outliers (which usually have higher errors than other samples) get more attention and dominance in the final error and impacting the model parameters.\n",
    "\n",
    "### 3.1.4. R-Squared\n",
    "\n",
    "R Squared is a measurement that tells you to what extent the proportion of variance in the dependent variable (target) is explained by the variance in the predictor variables. In simpler terms, while the coefficients estimate trends, R-squared represents the scatter around the line of best fit.\n",
    "\n",
    "For example, if the R² is 0.80, then 80% of the variation can be explained by the model’s inputs.\n",
    "If the R² is 1.0 or 100%, that means that all movements of the dependent variable can be entirely explained by the movements of the independent variables.\n",
    "To show a visual example, despite having the same line of best fit, the R² on the right is much higher than the one on the left.\n",
    "\n",
    "<img src=\"figures/r-squared.png\" alt=\"r-squared\" style=\"width: 800px;\"/>\n",
    "\n",
    "The equation for R² is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{R^2} = 1 - \\frac{\\mathsf{Explained\\ Variation}}{\\mathsf{Total\\ Variation}}\n",
    "\\end{equation}\n",
    "\n",
    "The Explained Variation is equal to the sum of squared residuals while the total variation is equal to the total sum of squared.\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathsf{SS_{residual}} = \\sum_{i=0}^{m} (y_i  -  \\hat{y}_i)^2  \\\\\n",
    "\\mathsf{SS_{total}} = \\sum_{i=0}^{m} (y_i  -  \\bar{y}_i)^2\n",
    "\\end{align*}\n",
    "\n",
    "###  3.1.5. Adjusted R-Squared\n",
    "\n",
    "Every additional independent variable added to a model always increases the R² value — therefore, a model with several independent variables may seem to be a better fit even if it isn’t. This is where Adjusted R² comes in. The adjusted R² compensates for each additional independent variable and only increases if the new term improves the model more than would be expected by chance.\n",
    "\n",
    "\n",
    "The formula for the Adjusted R-Squared taking into consideration the number of predictors $p$ of the model is then:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{R^2_{adjusted}} = 1 - \\frac{(1 - \\mathsf{R^2})(m-1)}{m-p-1}\n",
    "\\end{equation}\n",
    "\n",
    "While values are usually positive, they can be negative as well. This could happen if your $R^2$ is zero; After the adjustment, the value can dip below zero. This usually indicates that your model is a poor fit for your data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Regression metrics with python\n",
    "\n",
    "Let's consider the same diabetes example we have seen before. We will load our dataset, split it into a training and a testing sets. We will then fit and Linear Regression model and evaluate its performance over the training and the testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s load in the diabetes dataset, turn it into a data frame and define the columns’ names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (442, 10) (442,)\n"
     ]
    }
   ],
   "source": [
    "# Load the Diabetes dataset\n",
    "columns = [\"age\",\"sex\",\"bmi\",\"map\",\"tc\",\"ldl\",\"hdl\",\"tch\",\"ltg\",\"glu\"] # columns names\n",
    "diabetes = datasets.load_diabetes() # Call the diabetes dataset from sklearn\n",
    "df = pd.DataFrame(diabetes.data, columns=columns) # load the dataset as a pandas data frame\n",
    "y = diabetes.target # define the target variable (dependent variable) as y\n",
    "print(\"Dataset shape: \", df.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `train_test_split` function in order to make the split. The `test_size=0.2` inside the function indicates the percentage of the data that should be held over for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (353, 10) (353,)\n",
      "Testing set:  (89, 10) (89,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
    "print(\"Training set: \", X_train.shape, y_train.shape)\n",
    "print(\"Testing set: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Linear Regression model\n",
    "model_lin = LinearRegression(normalize=True)\n",
    "# Fitting Linear Regression model over the training set\n",
    "model_lin.fit(X_train, y_train)\n",
    "\n",
    "# predicting over training & testing datasets\n",
    "y_train_pred = model_lin.predict(X_train)\n",
    "y_test_pred = model_lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model over both sets using `sklearn.metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "MSE is 2877.1863682742664\n",
      "RMSE is 53.63941058843084\n",
      "MAE is 42.996280499750384\n",
      "R2 score is 0.5137499253152344\n",
      "\n",
      "\n",
      "The model performance for training set\n",
      "--------------------------------------\n",
      "MSE is 2821.8637175436693\n",
      "RMSE is 53.121217206909606\n",
      "MAE is 44.947255573196266\n",
      "R2 score is 0.5250886176863195\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation for training set\n",
    "mse_train = metrics.mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = (np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "mae_train = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('MSE is {}'.format(mse_train))\n",
    "print('RMSE is {}'.format(rmse_train))\n",
    "print('MAE is {}'.format(mae_train))\n",
    "print('R2 score is {}'.format(r2_train))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "mse_test = metrics.mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = (np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "mae_test = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = metrics.r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('MSE is {}'.format(mse_test))\n",
    "print('RMSE is {}'.format(rmse_test))\n",
    "print('MAE is {}'.format(mae_test))\n",
    "print('R2 score is {}'.format(r2_test))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Classification related metrics\n",
    "\n",
    "Classification is one of the most widely used problems in machine learning with various industrial applications, from face recognition, Youtube video categorization, content moderation, medical diagnosis, to text classification, hate speech detection on Twitter.\n",
    "\n",
    "There are various ways to evaluate a classification model, in this section we'll be covering some of the most popular ones below.\n",
    "\n",
    "### 3.3.1. Confusion Matrix (not a metric, but important to know!)\n",
    "\n",
    "One of the key concept in classification performance is the confusion matrix, which is a tabular visualization of the model predictions versus the ground-truth labels. Each row of confusion matrix represents the instances in a predicted class and each column represents the instances in an actual class.\n",
    "\n",
    "Let’s go through this with an example. Let’s assume we are building a binary classification to classify cat images from non-cat images. And let’s assume our test set has 1100 images (1000 non-cat images, and 100 cat images), with the below confusion matrix.\n",
    "\n",
    "<img src=\"figures/cats-cm.png\" alt=\"cats-cm\" style=\"width: 500px;\"/>\n",
    "\n",
    "* Out of 100 cat images the model has predicted 90 of them correctly and has mis-classified 10 of them. If we refer to the “cat” class as positive and the non-cat class as negative class, then 90 samples predicted as cat are considered as as true positive (TP), and the 10 samples predicted as non-cat are false negative (FN).\n",
    "\n",
    "* Out of 1000 non-cat images, the model has classified 940 of them correctly, and mis-classified 60 of them. The 940 correctly classified samples are referred as true negative (TN), and those 60 are referred as false positive (FP).\n",
    "\n",
    "As we can see diagonal elements of this matrix denote the correct prediction for different classes, while the off-diagonal elements denote the samples which are mis-classified.\n",
    "\n",
    "Below is a more general representation of the confusion matrix:\n",
    "\n",
    "<img src=\"figures/confusion-matrix.png\" alt=\"confusion-matrix\" style=\"width: 500px;\"/>\n",
    "\n",
    "Now that we have a better understanding of the confusion matrix, let’s get into the actual metrics.\n",
    "\n",
    "### 3.3.2. Classification Accuracy\n",
    "\n",
    "Classification accuracy is perhaps the simplest metrics one can imagine, and is defined as the number of correct predictions divided by the total number of predictions. \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} \n",
    "\\end{equation}\n",
    "\n",
    "So in the above example, out of 1100 samples 1030 are predicted correctly, resulting in a classification accuracy of:\n",
    "\n",
    "**Classification accuracy**= (90+940)/(1000+100)= 1030/1100= 93.6%\n",
    "\n",
    "\n",
    "### 3.3.3. Precision\n",
    "\n",
    "There are many cases in which classification accuracy is not a good indicator of your model performance. One of these scenarios is when your class distribution is imbalanced (one class is more frequent than others). In this case, even if you predict all samples as the most frequent class you would get a high accuracy rate, which does not make sense at all (because your model is not learning anything, and is just predicting everything as the top class). \n",
    "\n",
    "For example in our cat vs non-cat classification above, if the model predicts all samples as non-cat, it would result in a 1000/1100= 90.9%.\n",
    "\n",
    "Therefore we need to look at class specific performance metrics too. Precision is one of such metrics, which is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{Precision} = \\frac{TP}{TP + FP} \n",
    "\\end{equation}\n",
    "\n",
    "**The precision of the model is interpreted as follows: out of those positively predicted, what is the percentage of observations that are actually positive**.\n",
    "\n",
    "The precision of Cat and Non-Cat class in the above example can be calculated as:\n",
    "\n",
    "**Precision_Cat** = #samples correctly predicted cat/#samples predicted as cat = 90 / (90 + 60) = 60%\n",
    "\n",
    "**Precision_NonCat** = 940 / 950 = 98.9%\n",
    "\n",
    "As we can see the model has much higher precision in predicting non-cat samples, versus cats. This is not surprising, as model has seen more examples of non-cat images during training, making it better in classifying that class.\n",
    "\n",
    "\n",
    "###  3.3.4. Recall \n",
    "\n",
    "Recall is another important metric, which is defined as the fraction of samples from a class which are correctly predicted by the model. More formally:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{Recall} = \\frac{TP}{TP + FN} \n",
    "\\end{equation}\n",
    "\n",
    "Therefore, for our example above, the recall rate of cat and non-cat classes can be found as:\n",
    "\n",
    "**Recall_Cat** = 90 / 100 = 90%\n",
    "\n",
    "**Recall_NonCat** = 940 / 1000 = 94%\n",
    "\n",
    "### 3.3.5. F1 Score\n",
    "\n",
    "Depending on application, you may want to give higher priority to recall or precision. But there are many applications in which both recall and precision are important. Therefore, it is natural to think of a way to combine these two into a single metric. One popular metric which combines precision and recall is called F1-score, which is the harmonic mean of precision and recall defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{F1score} = 2*\\frac{\\mathsf{Precision} \\cdot \\mathsf{Recall}}{\\mathsf{Precision}+\\mathsf{Recall}} \n",
    "\\end{equation}\n",
    "\n",
    "#### Why is the F-Measure a harmonic mean and not an arithmetic mean of the Precision and Recall measures?\n",
    "\n",
    "This is just for a quick reference to understand the nature of the arithmetic mean and the harmonic mean with plots. As you can see from the plot, consider the X axis and Y axis as precision and recall, and the Z axis as the F1 Score. So, from the plot of the harmonic mean, both the precision and recall should contribute evenly for the F1 score to rise up unlike the Arithmetic mean.\n",
    "\n",
    "This is for the arithmetic mean.\n",
    "\n",
    "<img src=\"figures/arithmetic-mean.jpg\" alt=\"arithmetic-mean\" style=\"width: 300px;\"/>\n",
    "\n",
    "This is for the harmonic mean.\n",
    "\n",
    "<img src=\"figures/harmonic-mean.jpg\" alt=\"harmonic-mean\" style=\"width: 300px;\"/>\n",
    "\n",
    "So for our cat classification example, the F1-score can be calculated as:\n",
    "\n",
    "**F1-score**= 2 * 0.6 * 0.9  / (0.6 + 0.9) = 72%\n",
    "\n",
    "The generalized version of F-score is defined as below. As we can see F1-score is special case of $F_{\\beta }$ when $\\beta= 1$, where $\\beta$ is chosen such that recall is considered $\\beta$ times as important as precision.\n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle F_{\\beta }=(1+\\beta ^{2})\\cdot {\\frac {\\mathsf {Precision} \\cdot \\mathsf {Recall} }{(\\beta ^{2}\\cdot \\mathsf {Precision} )+\\mathsf {Recall} }}}\n",
    "\\end{equation}\n",
    "\n",
    "It is good to mention that there is always a trade-off between precision and recall of a model, if you want to make the precision too high, you would end up seeing a drop in the recall rate, and vice versa.\n",
    "\n",
    "### 3.3.6. Sensitivity and Specificity\n",
    "\n",
    "Sensitivity and specificity are two other popular metrics mostly used in medical and biology related fields, and are defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle \\mathsf{Sensitivity} = \\mathsf{Recall} = \\frac{TP}{TP+FN} }\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{Specificity} = \\mathsf{True \\ Negative \\ Rate} = \\frac{TN}{TN+FP}\n",
    "\\end{equation}\n",
    "\n",
    "### 3.3.7. Receiver Operating Characteristic Curve\n",
    "\n",
    "The receiver operating characteristic (ROC) curve is plot which shows the performance of a binary classifier as function of its cut-off threshold. It essentially shows the true positive rate (TPR) against the false positive rate (FPR) for various threshold values. Let’s explain more.\n",
    "Many of the classification models are probabilistic, i.e. they predict the probability of a sample being a cat. They then compare that output probability with some cut-off threshold and if it is larger than the threshold they predict its label as cat, otherwise as non-cat. As an example your model may predict the below probabilities for 4 sample images: [0.45, 0.6, 0.7, 0.3]. Then depending on the threshold values below, you will get different labels:\n",
    "\n",
    "* cut-off= 0.5: predicted-labels= [0,1,1,0] (default threshold)\n",
    "* cut-off= 0.2: predicted-labels= [1,1,1,1]\n",
    "* cut-off= 0.8: predicted-labels= [0,0,0,0]\n",
    "\n",
    "As you can see by varying the threshold values, we will get completely different labels. And as you can imagine each of these scenarios would result in a different precision and recall (as well as TPR, FPR) rates.\n",
    "\n",
    "ROC curve essentially finds out the TPR and FPR for various threshold values and plots TPR against the FPR. A sample ROC curve is shown in Figure below.\n",
    "\n",
    "<img src=\"figures/roc-curve.png\" alt=\"roc-curve\" style=\"width: 500px;\"/>\n",
    "\n",
    "As we can see from this example, the lower the cut-off threshold on positive class, the more samples predicted as positive class, i.e. higher true positive rate (recall) and also higher false positive rate (corresponding to the right side of this curve). Therefore, there is a trade-off between how high the recall could be versus how much we want to bound the error (FPR).\n",
    "ROC curve is a popular curve to look at overall model performance and pick a good cut-off threshold for the model.\n",
    "\n",
    "### 3.3.8. AUC\n",
    "\n",
    "The area under the curve (AUC), is an aggregated measure of performance of a binary classifier on all possible threshold values (and therefore it is threshold invariant).\n",
    "\n",
    "AUC calculates the area under the ROC curve, and therefore it is between 0 and 1. **One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example**.\n",
    "\n",
    "<img src=\"figures/AUC.png\" alt=\"AUC\" style=\"width: 400px;\"/>\n",
    "\n",
    "On high-level, the higher the AUC of a model the better it is. But sometimes threshold independent measure is not what you want, e.g. you may care about your model recall and require that to be higher than 99% (while it has a reasonable precision or FPR). In that case, you may want to tune your model threshold such that it meets your minimum requirement on those metrics (and you may not care if you model AUC is not too high).\n",
    "\n",
    "Therefore in order to decide how to evaluate your classification model performance, perhaps you want to have a good understanding of the business/problem requirement and the impact of low recall vs. low precision, and decide what metric to optimize for.\n",
    "\n",
    "From a practical standpoint, a classification model which outputs probabilities is preferred over a single label output, as it provides the flexibility of tuning the threshold such that it meets your minimum recall/precision requirements. Not all models provide this nice probabilistic outputs though, e.g. SVM does not provide a simple probability as an output (although it provides margin which can be used to tune the decision, but it is not as straightforward and interpretable as having output probabilities)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Classification metrics with python\n",
    "\n",
    "In the proceeding example, we’ll take a look at all the metrics in action. For simplicity, we’ll be using one of the datasets provided by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the breast cancer dataset, and explore available features and target. The breast cancer dataset is a classic and very easy binary classification dataset. The objective of our model is to predict whether a patient has breast cancer or not given the available features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()\n",
    "\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare our data for training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll be using the logistic regression classifier but any classification algorithm will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train, y_train)\n",
    "y_test_pred = lgr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 58,   5],\n",
       "       [  6, 102]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` also offers a nice function to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x12a64b750>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_confusion_matrix(lgr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Accuracy of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935672514619883"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "The recall of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92063492, 0.94444444])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test, y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "The precision of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90625   , 0.95327103])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test, y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1score\n",
    "\n",
    "The f1score of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91338583, 0.94883721])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic - AUC\n",
    "\n",
    "In able to plot ROC or evaluate AUC, we need the probability outputs of our model instead of the final prediction.\n",
    "\n",
    "We call the `predict_proba` method rather than `predict` in order to obtain a list of probabilities which represent the likelihood that a sample falls under a given category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = lgr.predict_proba(X_test)\n",
    "malignant_probs = probs[:,1]\n",
    "\n",
    "# calculating roc arguments\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, malignant_probs)\n",
    "# calculating auc\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,8])\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'y', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter Tuning\n",
    "\n",
    "Choosing the right hyperparameters for your machine learning algorithm is a crucial task, since it can make a big difference on the performance of a model. \n",
    "\n",
    "Machine Learning models are composed of two different types of parameters:\n",
    "\n",
    "* **Hyperparameters** = are all the parameters which can be arbitrarily set by the user before starting training (eg. Learning rate, regularization parameter, batch size in the mini-batch gradient descent...).\n",
    "\n",
    "* Model **parameters** = are instead learned during the model training (eg. weights in Linear Regression, Neural Networks...).\n",
    "\n",
    "The model parameters define how to use input data to get the desired output and are learned at training time. Instead, Hyperparameters determine how our model is structured in the first place.\n",
    "Hyperparameter tuning is a type of optimization problem. We have a set of hyperparameters and we aim to find the right combination of their values which can help us to find either the minimum (eg. loss) or the maximum (eg. accuracy) of a function.\n",
    "\n",
    "<img src=\"figures/hyperparameter-tuning.png\" alt=\"hyperparameter-tuning\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Grid search\n",
    "\n",
    "Grid search is a method by which we create sets of possible hyper-parameters values for each hyper-parameter, then test them against each other in a “grid.” \n",
    "\n",
    "The recipe below evaluates different $\\lambda$ values for the regularized linear regression algorithm we have seen above (a Linear Regression with an $L_2$ regularization is called Ridge Regression) on the standard diabetes dataset. This is a one-dimensional grid search.\n",
    "\n",
    "Grid Search can be implemented in Python using `scikit-learn` `GridSearchCV()` function. The `verbose` parameter dictates whether the function will print information as it runs, and the `cv` parameter refers to cross validation folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (353, 10) (353,)\n",
      "Testing set:  (89, 10) (89,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 2 sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2)\n",
    "print(\"Training set: \", X_train.shape, y_train.shape)\n",
    "print(\"Testing set: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "RMSE:  55.08\n",
      "Best regularization parameter:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "\n",
    "# prepare a range of alpha values to test\n",
    "grid = {'alpha': [1,0.1,0.01,0.001,0.0001,0]}\n",
    "\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "gsearch = GridSearchCV(estimator=model, param_grid=grid, scoring=\"neg_mean_squared_error\", verbose=1)\n",
    "gsearch.fit(X_train, y_train)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print('RMSE: ', np.round(np.sqrt(-1*gsearch.best_score_), 2))\n",
    "print('Best regularization parameter: ', gsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating RMSE performance on the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  54.37\n"
     ]
    }
   ],
   "source": [
    "rmse_test = gsearch.score(X_test, y_test)\n",
    "print('RMSE: ', np.round(np.sqrt(-1*rmse_test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Random search\n",
    "\n",
    "As its name suggests, Random Search uses random combinations of hyperparameters. This means that not all of the parameter values are tried, and instead, parameters will be sampled with fixed numbers of iterations given by `n_iter` in the `RandomizedSearchCV()` function.\n",
    "\n",
    "Random Search would be advised to use over Grid Search when the searching space is high meaning that there are more than 3 dimensions as Random Search is able to explore a wider hyperparameter space. In the below example, grid search only tested three unique values for each hyperperameter, whereas the random search tested 9 unique values for each. That means if one hyperparameter is more important than the others, random search will be better. Think of it this way: if hyperparameter 2 doesn’t really matter, then we would want 9 different hyperparameter 1 values to test instead of 3. The same holds true for higher dimensions (more hyperparameters).\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/gs-vs-rs.png\" alt=\"/gs-vs-rs\" width=\"600px\"/>\n",
    "    <span class=\"caption\">With grid search, nine trials only test three distinct places. With random search, all nine trails explore distinct values.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will use a logistic regression (a linear algorithm used for classification) which has many different hyperparameters. For this example we will only consider these hyperparameters:\n",
    "\n",
    "* The penalty (The regularization type L1 or L2)\n",
    "* The C value (The regularization parameter)\n",
    "\n",
    "The data set we will be using is the classic and simple iris data set. First we need to import the things we need, as well as separate the target variable from the independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (120, 4) (120,)\n",
      "Testing set:  (30, 4) (30,)\n"
     ]
    }
   ],
   "source": [
    "# Split the 2 data into 2 sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=1)\n",
    "print(\"Training set: \", X_train.shape, y_train.shape)\n",
    "print(\"Testing set: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.98\n",
      "Best regularization penalty type:  l2\n",
      "Best regularization parameter:  2.7825594022071245\n"
     ]
    }
   ],
   "source": [
    "# prepare a uniform distribution to sample for the penalty & C hyperparameters\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0, 4, num=10)\n",
    "grid = dict(C=C, penalty=penalty)\n",
    "\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "logistic = LogisticRegression()\n",
    "rsearch = RandomizedSearchCV(estimator=logistic, param_distributions=grid, n_iter=50, scoring = 'accuracy')\n",
    "\n",
    "rsearch.fit(X_train, y_train)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print('Accuracy: ', np.round(rsearch.best_score_, 2))\n",
    "print('Best regularization penalty type: ', rsearch.best_estimator_.penalty)\n",
    "print('Best regularization parameter: ', rsearch.best_estimator_.C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Engineering Techniques\n",
    "\n",
    "Algorithms require features with some specific characteristic to work properly. Here, the need for feature engineering arises. Feature engineering efforts mainly have two goals:\n",
    "\n",
    "* Preparing the proper input dataset, compatible with the machine learning algorithm requirements.\n",
    "* Improving the performance of machine learning models.\n",
    "\n",
    "> The features you use influence more than everything else the result. No algorithm alone, to my knowledge, can supplement the information gain given by correct feature engineering.\n",
    "— Luca Massaron\n",
    "\n",
    "According to a survey in Forbes, data scientists spend 80% of their time on data preparation.\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/forbes.png\" alt=\"forbes\" width=\"600px\"/>\n",
    "    <span class=\"caption\">Forbes Survey (<a href=\"https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/\">Source</a>)\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Data leakage\n",
    "\n",
    "When training a machine learning model, we normally aim for the model that scores the highest on some metric, such as accuracy. Naturally, then, when we train a model that appears to score very well on our validation or test data-set, we select it as a well-performing model and productionize/finalize it.\n",
    "However, have you ever encountered a situation in which a model performs well during testing, but fails to achieve the same level of performance during real-world usage? For example, has your model reached 99% accuracy during testing, but as soon as it is productionized and acts on real data, it fails to get anywhere near that level of performance?\n",
    "Such a discrepancy between test performance and real-world performance is often explained by a phenomenon called **data leakage**.\n",
    "\n",
    "Data leakage refers to a mistake make by the creator of a machine learning model in which they accidentally share information between the test and training data-sets. Typically, when splitting a data-set into testing and training sets, the goal is to ensure that no data is shared between the two. This is because the test set’s purpose is to simulate real-world, unseen data.\n",
    "\n",
    "\n",
    "A very common error that people make is to leak information in the data **pre-processing step** of machine learning. It is essential that these transformations only have knowledge of the training set, even though they are applied to the test set as well. For example, if you decide that you want to run PCA as a pre-processing step, you should fit your PCA model on only the training set. Then, to apply it to your test set, you would only call its transform method (in the case of a `scikit-learn` model) on the test set. If, instead, you fit your pre-processor on the entire data-set, you will leak information from the test set, since the parameters of the pre-processing model will be fitted with knowledge of the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use the loans prediction dataset provided in the following [competition](https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/) organized by Analytics Vidhya in order to explore some **popular feature engineering techniques**. \n",
    "\n",
    "In python, scikit-learn library has a pre-built functionality under `sklearn.preprocessing`. There are many more options for pre-processing which we’ll explore.\n",
    "\n",
    "Now, lets get started by importing important packages and the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv(\"data/data_loans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LoanID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>LoanAmountTerm</th>\n",
       "      <th>CreditHistory</th>\n",
       "      <th>PropertyArea</th>\n",
       "      <th>LoanStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LoanID Gender Married Dependents     Education SelfEmployed  \\\n",
       "0  LP001002   Male      No          0      Graduate           No   \n",
       "1  LP001003   Male     Yes          1      Graduate           No   \n",
       "2  LP001005   Male     Yes          0      Graduate          Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate           No   \n",
       "4  LP001008   Male      No          0      Graduate           No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  LoanAmountTerm  \\\n",
       "0             5849                0.0         NaN           360.0   \n",
       "1             4583             1508.0       128.0           360.0   \n",
       "2             3000                0.0        66.0           360.0   \n",
       "3             2583             2358.0       120.0           360.0   \n",
       "4             6000                0.0       141.0           360.0   \n",
       "\n",
       "   CreditHistory PropertyArea LoanStatus  \n",
       "0            1.0        Urban          Y  \n",
       "1            1.0        Rural          N  \n",
       "2            1.0        Urban          Y  \n",
       "3            1.0        Urban          Y  \n",
       "4            1.0        Urban          Y  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 13)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's seperate our features from our target variable and split the dataframe into 2 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (491, 11) (491,)\n",
      "Testing set:  (123, 11) (123,)\n"
     ]
    }
   ],
   "source": [
    "y, X = data.pop(\"LoanStatus\"), data\n",
    "X.pop(\"LoanID\")\n",
    "\n",
    "# Split the 2 data into 2 sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print(\"Training set: \", X_train.shape, y_train.shape)\n",
    "print(\"Testing set: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Missing values imputation\n",
    "\n",
    "Handling missing values is an essential preprocessing task that can drastically deteriorate your model when not done with sufficient care. Reasons for the missing values might be human errors, interruptions in the data flow, privacy concerns, and so on. Whatever is the reason, missing values affect the performance of the machine learning models.\n",
    "\n",
    "A few questions should come up when handling missing values:\n",
    "\n",
    "> Do I have missing values? How are they expressed in the data? Should I withhold samples with missing values? Or should I replace them? If so, which values should they be replaced with?\n",
    "\n",
    "Some machine learning platforms automatically drop the rows which include missing values in the model training phase and it decreases the model performance because of the reduced training set size. On the other hand, most of the algorithms do not accept datasets with missing values and gives an error.\n",
    "\n",
    "Before starting handling missing values it is important to identify the missing values and know with which value they are replaced. You should be able to find this out by combining the metadata information with exploratory analysis.\n",
    "Once you know a bit more about the missing data you have to decide whether or not you want to keep entries with missing data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of missing values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                9\n",
       "Married               2\n",
       "Dependents           10\n",
       "Education             0\n",
       "SelfEmployed         24\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           17\n",
       "LoanAmountTerm       10\n",
       "CreditHistory        44\n",
       "PropertyArea          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most simple solution to the missing values is to drop the rows or the entire column. There is not an optimum threshold for dropping but you can use 50% as an example value and try to drop the rows and columns which have missing values with higher than this threshold. In our examples, we don't have such rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing set should represent unseen data, that's why when doing feature engineering, we will apply exactly the same transformations applied to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "# Dropping columns with missing value rate higher than threshold in the training set\n",
    "X_train = X_train[X_train.columns[X_train.isnull().mean() < threshold]]\n",
    "# Aligning the test dataset columns with the train dataset\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1)\n",
    "\n",
    "# Dropping rows with missing value rate higher than threshold\n",
    "X_train = X_train.loc[X_train.isnull().mean(axis=1) < threshold]\n",
    "X_test = X_test.loc[X_test.isnull().mean(axis=1) < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (491, 11) (491,)\n",
      "Testing set:  (123, 11) (123,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set: \", X_train.shape, y_train.shape)\n",
    "print(\"Testing set: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. Numerical imputation\n",
    "Imputation is a more preferable option rather than dropping because it preserves the data size. However, there is an important selection of what you impute to the missing values. \n",
    "\n",
    "Except for the case of having a default value for missing values, a popular imputation method is to use the medians of the columns. As the averages of the columns are sensitive to the outlier values, while medians are more solid in this respect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Married',\n",
       " 'Dependents',\n",
       " 'SelfEmployed',\n",
       " 'LoanAmount',\n",
       " 'LoanAmountTerm',\n",
       " 'CreditHistory']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns with missing values\n",
    "missing_columns = X_train.isna().sum()[X_train.isna().sum()>0].index.values.tolist()\n",
    "missing_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's plot a histogram of our numerical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x792 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# numerical columns\n",
    "numeric_columns = X_train.dtypes[((X_train.dtypes==\"float64\")|(X_train.dtypes==\"int64\"))].index.values.tolist()\n",
    "\n",
    "#plot a histogram of numerical columns with missing values\n",
    "X_train[numeric_columns].hist(figsize=[11,11]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's impute missing values in column `CreditHistory` with 1, and the 2 other numercial columns `LoanAmount` & `LoanAmountTerm` with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Let's define a constant imputer in order to impute missing values in CreditHistory with 1.\n",
    "imp_constant = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=1)\n",
    "X_train[[\"CreditHistory\"]] = imp_constant.fit_transform(X_train[[\"CreditHistory\"]])\n",
    "X_test[[\"CreditHistory\"]] = imp_constant.transform(X_test[[\"CreditHistory\"]])\n",
    "\n",
    "# Let's define an imputer with median strategy in order to impute missing values in LoanAmount and LoanAmountTerm\n",
    "cols = [\"LoanAmount\", \"LoanAmountTerm\"]\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train[cols] = imp_median.fit_transform(X_train[cols])\n",
    "X_test[cols] = imp_median.transform(X_test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of missing values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                9\n",
       "Married               2\n",
       "Dependents           10\n",
       "Education             0\n",
       "SelfEmployed         24\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount            0\n",
       "LoanAmountTerm        0\n",
       "CreditHistory         0\n",
       "PropertyArea          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. Categorical imputation\n",
    "\n",
    "Replacing the missing values with the maximum occurred value in a column is a good option for handling categorical columns. But if you think the values in the column are distributed uniformly and there is not a dominant value, imputing a category like “Other” might be more sensible, because in such a case, your imputation is likely to converge a random selection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_columns = X_train.dtypes[((X_train.dtypes==\"object\"))].index.values.tolist()\n",
    "\n",
    "fig, ax = plt.subplots(2, int(len(categorical_columns)/2), figsize=(16,8))\n",
    "for i, categorical_col in enumerate(X_train[categorical_columns]):\n",
    "    X_train[categorical_col].value_counts().plot(\"bar\", ax=sum(ax.tolist(), [])[i]).set_title(categorical_col)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's impute the missing values in the columns `Married`,` Sex`, `Dependent` with the dominant value (most frequent), while in the column` SelfEmployed` with a constant \"UNK\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values in columns Married, Gender, Dependents with the dominant (most frequent) value\n",
    "cols = [\"Married\", \"Gender\", \"Dependents\"]\n",
    "imp_most_frequent = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "X_train[cols] = imp_most_frequent.fit_transform(X_train[cols])\n",
    "X_test[cols] = imp_most_frequent.transform(X_test[cols])\n",
    "\n",
    "# Imputing column column SelfEmployed with a constant 'UNK'\n",
    "imp_constant = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='UNK')\n",
    "X_train[[\"SelfEmployed\"]] = imp_constant.fit_transform(X_train[[\"SelfEmployed\"]])\n",
    "X_test[[\"SelfEmployed\"]] = imp_constant.transform(X_test[[\"SelfEmployed\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of missing values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "SelfEmployed         0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "LoanAmountTerm       0\n",
       "CreditHistory        0\n",
       "PropertyArea         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Scaling\n",
    "\n",
    "In most cases, the numerical features of the dataset do not have a certain range and they differ from each other. In real life, it is nonsense to expect age and income columns to have the same range. But from the machine learning point of view, how can these two columns be compared?\n",
    "\n",
    "Scaling solves this problem. The continuous features become identical in terms of the range, after a scaling process. This process is not mandatory for many algorithms, but it might be still nice to apply. However, the algorithms based on distance calculations such as k-NN or k-Means need to have scaled continuous features as model input.\n",
    "\n",
    "**We will talk more about the importance of scaling in the next chapter.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` provides a tool `MinMaxScaler` that will scale down all the features between 0 and 1. Mathematical formula for MinMaxScaler is:\n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle x'={\\frac {x-{\\text{min}}(x)}{{\\text{max}}(x)-{\\text{min}}(x)}}}\n",
    "\\end{equation}\n",
    "\n",
    "We will only scale the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmc = MinMaxScaler()\n",
    "scaled_columns = [x for x in numeric_columns if x != 'CreditHistory']\n",
    "\n",
    "X_train[scaled_columns] = mmc.fit_transform(X_train[scaled_columns])\n",
    "X_test[scaled_columns] = mmc.transform(X_test[scaled_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x792 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot a histogram of numerical columns with missing values\n",
    "X_train[numeric_columns].hist(figsize=[11,11]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Label encoding\n",
    "\n",
    "In previous sections, we did the pre-processing for continuous numeric features. But, our data set has other features too such as Gender, Married, Dependents, SelfEmployed and Education. All these categorical features have string values. And algorithms work with numbers!\n",
    "\n",
    "If we feed the categorical features to a logistic regression model for example, we get an error saying that it cannot convert string to float. So, what’s actually happening here is that most learners in `sklearn` needs numeric arrays. Features having string values cannot be handled automatically.\n",
    "\n",
    "This encoding type is better for **ordinal categorical data** and if the **number of categorical features in the dataset** is huge, you may often use label encoding.\n",
    "\n",
    "`Sklearn` provides a very efficient tool for encoding the levels of a categorical features into numeric values. `LabelEncoder` encode labels with value between 0 and n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>LoanAmountTerm</th>\n",
       "      <th>CreditHistory</th>\n",
       "      <th>PropertyArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>0.052566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170767</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>0.042461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125904</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>0.051738</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.146165</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089725</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183792</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender Married Dependents Education SelfEmployed  ApplicantIncome  \\\n",
       "291    Male     Yes          2  Graduate           No         0.052566   \n",
       "507    Male      No          0  Graduate           No         0.042461   \n",
       "328  Female     Yes          0  Graduate           No         0.051738   \n",
       "609  Female      No          0  Graduate           No         0.034014   \n",
       "69   Female      No          0  Graduate           No         0.051330   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  LoanAmountTerm  CreditHistory PropertyArea  \n",
       "291           0.000000    0.170767         0.74359            0.0    Semiurban  \n",
       "507           0.000000    0.125904         0.74359            1.0        Urban  \n",
       "328           0.058824    0.146165         0.74359            1.0        Urban  \n",
       "609           0.000000    0.089725         0.74359            1.0        Rural  \n",
       "69            0.000000    0.183792         0.74359            0.0    Semiurban  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's label encode binary catagorical columns only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Iterating over all the common columns in train and test\n",
    "for col in [\"Gender\", \"Married\", \"Education\"]:\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>LoanAmountTerm</th>\n",
       "      <th>CreditHistory</th>\n",
       "      <th>PropertyArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.052566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170767</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.042461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125904</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.051738</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.146165</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089725</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183792</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married Dependents  Education SelfEmployed  ApplicantIncome  \\\n",
       "291       1        1          2          0           No         0.052566   \n",
       "507       1        0          0          0           No         0.042461   \n",
       "328       0        1          0          0           No         0.051738   \n",
       "609       0        0          0          0           No         0.034014   \n",
       "69        0        0          0          0           No         0.051330   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  LoanAmountTerm  CreditHistory PropertyArea  \n",
       "291           0.000000    0.170767         0.74359            0.0    Semiurban  \n",
       "507           0.000000    0.125904         0.74359            1.0        Urban  \n",
       "328           0.058824    0.146165         0.74359            1.0        Urban  \n",
       "609           0.000000    0.089725         0.74359            1.0        Rural  \n",
       "69            0.000000    0.183792         0.74359            0.0    Semiurban  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. One-hot encoding\n",
    "\n",
    "Depending on the data, label encoding introduces a new problem. For example, we have encoded a set of `Gender` into numerical data. This is actually categorical data and there is no relation, of any kind, between the rows.\n",
    "The problem here is, since there are different numbers in the same column, the model will misunderstand the data and will be confused into thinking that there's some kind of order or hierarchy, 0 < 1 < 2. But this isn’t the case at all. To overcome this problem, we use One Hot Encoder.\n",
    "\n",
    "We mainly use one hot encoding with **nominal data**.\n",
    "\n",
    "One-hot encoding is one of the most common encoding methods in machine learning. This method spreads the values in a column to multiple flag columns and assigns 0 or 1 to them. These binary values express the relationship between grouped and encoded column.\n",
    "\n",
    "This method changes your categorical data, which is challenging to understand for algorithms, to a numerical format and enables you to group your categorical data without losing any information. \n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/one-hot.png\" alt=\"one-hot\" width=\"600px\"/>\n",
    "    <span class=\"caption\">One hot encoding example on City column\n",
    "    </span>\n",
    "</div>\n",
    "\n",
    "In `sklearn`, we can use the `OneHotEncoder` class which creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse parameter). 2 important parameters:\n",
    "\n",
    "* **drop: ‘first’ or a array-like of shape (n_features,), default=None**\n",
    "\n",
    "    Specifies a methodology to use to drop one of the categories per feature. This is useful in situations where perfectly collinear features cause problems, such as when feeding the resulting data into a neural network or an unregularized regression.\n",
    "    \n",
    "    \n",
    "* **handle_unknown: {‘error’, ‘ignore’}, default=’error’**\n",
    "\n",
    "    Whether to raise an error or ignore if an unknown categorical feature is present during transform (default is to raise). When this parameter is set to ‘ignore’ and an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(drop = None, handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# Define categorical to be one hot encoded\n",
    "ohe_cols = [\"Dependents\", \"SelfEmployed\", \"PropertyArea\"]\n",
    "\n",
    "# Encode categorical columns, and store results in a new dataframe\n",
    "X_train_encoded = pd.DataFrame(ohe.fit_transform(X_train[ohe_cols]), index=X_train.index)\n",
    "X_test_encoded = pd.DataFrame(ohe.transform(X_test[ohe_cols]), index=X_test.index)\n",
    "\n",
    "# Retrieve encoded columns names\n",
    "X_train_encoded.columns = ohe.get_feature_names(ohe_cols)\n",
    "X_test_encoded.columns = ohe.get_feature_names(ohe_cols)\n",
    "\n",
    "# Drop initial columns \n",
    "X_train.drop(ohe_cols ,axis=1, inplace=True)\n",
    "X_test.drop(ohe_cols ,axis=1, inplace=True)\n",
    "\n",
    "# Add encoded columns to initial dataset\n",
    "X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_encoded ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>LoanAmountTerm</th>\n",
       "      <th>CreditHistory</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>Dependents_1</th>\n",
       "      <th>Dependents_2</th>\n",
       "      <th>Dependents_3+</th>\n",
       "      <th>SelfEmployed_No</th>\n",
       "      <th>SelfEmployed_UNK</th>\n",
       "      <th>SelfEmployed_Yes</th>\n",
       "      <th>PropertyArea_Rural</th>\n",
       "      <th>PropertyArea_Semiurban</th>\n",
       "      <th>PropertyArea_Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170767</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125904</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051738</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.146165</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089725</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183792</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Education  ApplicantIncome  CoapplicantIncome  \\\n",
       "291       1        1          0         0.052566           0.000000   \n",
       "507       1        0          0         0.042461           0.000000   \n",
       "328       0        1          0         0.051738           0.058824   \n",
       "609       0        0          0         0.034014           0.000000   \n",
       "69        0        0          0         0.051330           0.000000   \n",
       "\n",
       "     LoanAmount  LoanAmountTerm  CreditHistory  Dependents_0  Dependents_1  \\\n",
       "291    0.170767         0.74359            0.0           0.0           0.0   \n",
       "507    0.125904         0.74359            1.0           1.0           0.0   \n",
       "328    0.146165         0.74359            1.0           1.0           0.0   \n",
       "609    0.089725         0.74359            1.0           1.0           0.0   \n",
       "69     0.183792         0.74359            0.0           1.0           0.0   \n",
       "\n",
       "     Dependents_2  Dependents_3+  SelfEmployed_No  SelfEmployed_UNK  \\\n",
       "291           1.0            0.0              1.0               0.0   \n",
       "507           0.0            0.0              1.0               0.0   \n",
       "328           0.0            0.0              1.0               0.0   \n",
       "609           0.0            0.0              1.0               0.0   \n",
       "69            0.0            0.0              1.0               0.0   \n",
       "\n",
       "     SelfEmployed_Yes  PropertyArea_Rural  PropertyArea_Semiurban  \\\n",
       "291               0.0                 0.0                     1.0   \n",
       "507               0.0                 0.0                     0.0   \n",
       "328               0.0                 0.0                     0.0   \n",
       "609               0.0                 1.0                     0.0   \n",
       "69                0.0                 0.0                     1.0   \n",
       "\n",
       "     PropertyArea_Urban  \n",
       "291                 0.0  \n",
       "507                 1.0  \n",
       "328                 1.0  \n",
       "609                 0.0  \n",
       "69                  0.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6. Other feature engineering techniques & references\n",
    "\n",
    "The aim of this section is to familiarize you with the basic feature engineering techniques and have a deeper understanding of the situations of where to apply those techniques.\n",
    "\n",
    "These methods work because of the underlying assumptions of the algorithms. This is by no means an exhaustive list of the methods. Other type of preprocessing techniques include:\n",
    "\n",
    "### 5.6.1. Handling outliers\n",
    "\n",
    "Data outliers can spoil and mislead the training process resulting in longer training times, less accurate models and ultimately poorer results.\n",
    "\n",
    "Before mentioning some techniques for how outliers can be handled, It's good to state that the best way to detect the outliers is to demonstrate the data visually. All other statistical methodologies are open to making mistakes, whereas visualizing the outliers might give a chance to take a decision with high precision.\n",
    "\n",
    "There are many different methods of dealing with outliers, here are some popular techniques:\n",
    "\n",
    "* **Univariate method**: This method looks for data points with extreme values on one variable.\n",
    "\n",
    "    For more details about the statistical methods used for outlier detection, check [this blog](http://colingorrie.github.io/outlier-detection.html)\n",
    "\n",
    "\n",
    "* **Multivariate method**: Here we look for unusual combinations on all the variables.\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/multivariate-outlier-example.jpg\" alt=\"multivariate-outlier-example\" width=\"500px\"/>\n",
    "</div>\n",
    "\n",
    "* **Minkowski error**: This method reduces the contribution of potential outliers in the training process.\n",
    "\n",
    "    Unlike the univariate and multivariate methods, it doesn't detect and clean the outliers. Instead, it reduces the impact that outliers will have in the model.\n",
    "\n",
    "    The Minkowski error is a loss index that is more insensitive to outliers than the standard mean squared error. The mean squared error raises each instance error to the square, making a too big contribution of outliers to the total error. The Minkowski error solves that by raising each instance error to a number smaller than 2, for instance 1.5. This reduces the contribution of outliers to the total error. \n",
    "\n",
    "\n",
    "### 5.6.2. Binning/Bucketing\n",
    "\n",
    "Binning can be applied on both categorical and numerical data:\n",
    "\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/binning.png\" alt=\"binning\" width=\"400px\" style=\"padding:20px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "If you choose to bucketize your numerical features, be clear about how you are setting the boundaries and which type of bucketing you’re applying:\n",
    "\n",
    "* **Buckets with equally spaced boundaries**: the boundaries are fixed and encompass the same range (for example, 0-4 degrees, 5-9 degrees, and 10-14 degrees). Some buckets could contain many points, while others could have few or none.\n",
    "\n",
    "* **Buckets with quantile boundaries**: each bucket has the same number of points. The boundaries are not fixed and could encompass a narrow or wide span of values. \n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"figures/bucketizing-1.svg\" alt=\"bucketizing-1\"/>\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "     <img src=\"figures/bucketizing-2.svg\" alt=\"bucketizing-2\"/>\n",
    "  </div>\n",
    "</div>\n",
    "    \n",
    "\n",
    "\n",
    "Bucketing with equally spaced boundaries is an easy method that works for a lot of data distributions. For skewed data, however, try bucketing with quantile bucketing.\n",
    "\n",
    "### 5.6.3. Log transform\n",
    "\n",
    "Logarithm transformation is one of the most commonly used mathematical transformations in feature engineering. What are the benefits of log transform:\n",
    "\n",
    "It helps to handle skewed data and after transformation, the distribution becomes more approximate to normal.\n",
    "In most of the cases the magnitude order of the data changes within the range of the data. For instance, the difference between the ages of 15 and 20 is not equal to the ages 65 and 70. In terms of years, yes, they are identical, but for all other aspects, 5 years of difference in young ages mean a higher magnitude difference. This type of data comes from a multiplicative process and log transform normalizes the magnitude differences like that.\n",
    "\n",
    "It also decreases the effect of the outliers, due to the normalization of magnitude differences and the model becomes more robust.\n",
    "\n",
    "A critical note: The data you apply log transform must have only positive values, otherwise you receive an error. Also, you can add 1 to your data before transforming it. Thus, you ensure the output of the transformation to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
